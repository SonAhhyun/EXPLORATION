{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "isolated-radiation",
   "metadata": {},
   "source": [
    "<h1> 뉴스 요약봇 만들기 </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-farming",
   "metadata": {},
   "source": [
    "### 학습 목표\n",
    "\n",
    "--- \n",
    "\n",
    "- Extractive/Abstractive summarization 이해하기\n",
    "- 단어장 크기를 줄이는 다양한 text normalization 적용해보기\n",
    "- seq2seq의 성능을 Up시키는 Attention Mechanism 적용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-stroke",
   "metadata": {},
   "source": [
    "![](https://github.com/MulderKim/EXPLORATION/blob/main/10/etc/E-21-1.png?raw=true)\n",
    "\n",
    "텍스트 요약(Text Summarization)이란 긴 길이의 문서(Document) 원문을 핵심 주제만으로 구성된 짧은 요약(Summary) 문장들로 변환하는 것\n",
    "\n",
    "중요한 것은 요약 전후에 정보 손실 발생이 최소화되어야 한다는 점\n",
    "\n",
    "텍스트 요약은 크게 추출적 요약(Extractive Summarization)과 추상적 요약(Abstractive Summarization)의 두 가지 접근으로 나누어볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-broadcast",
   "metadata": {},
   "source": [
    "### 추출적 요약(Extractive Summarization)\n",
    "\n",
    "단어 그대로 원문에서 문장들을 추출해서 요약하는 방식으로 결과로 나온 문장들 간의 호응이 자연스럽지 않을 수 있다. \n",
    "\n",
    "딥 러닝보다는 주로 전통적인 머신 러닝 방식에 속하는 텍스트 랭크(TextRank)와 같은 알고리즘을 사용해서 이 방법을 사용.\n",
    "\n",
    "가장 대표적인 것이 네이버 뉴스 서비스에 있는 요약봇 기능으로 TextRank 알고리즘을 통해 해당 기사를 가장 잘 대표하는 단어들로 이루어진 핵심문장을 아주 효과적으로 찾아내기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-samoa",
   "metadata": {},
   "source": [
    "### 추상적 요약(Abstractive Summarization)\n",
    "\n",
    "두 번째 방식인 추상적 요약은 추출적 요약보다 좀 더 흥미로운 접근을 사용하는데, 원문으로부터 내용이 요약된 새로운 문장을 생성해내는 것. \n",
    "\n",
    "여기서 새로운 문장이라는 것은 결과로 나온 문장이 원문에 원래 없던 문장일 수도 있다는 것을 의미하며 \n",
    "\n",
    "자연어 처리 분야 중 자연어 생성(Natural Language Generation, NLG)의 영역으로 추출적 요약은 원문을 구성하는 문장 중 \n",
    "\n",
    "어느 것이 요약문에 들어갈 핵심문장인지를 판별한다는 점에서 문장 분류(Text Classification) 문제로 볼 수 있다.\n",
    "\n",
    "RNN으로 추상적 요약 방식을 구현한다.\n",
    "\n",
    "ML 분야의 선구자라고 할 수 있는 기업 '구글(Google)'은 뉴스 기사 내용으로부터 자동으로 뉴스 제목을 뽑아내는 텍스트 요약 모델을 구현했었다고 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-parliament",
   "metadata": {},
   "source": [
    "## 인공 신경망으로 텍스트 요약 훈련시키기\n",
    "\n",
    "seq2seq 모델을 통해서 Abstractive summarization 방식의 텍스트 요약기를 만들기. \n",
    "\n",
    "seq2seq은 두 개의 RNN 아키텍처를 사용하여 입력 시퀀스로부터 출력 시퀀스를 생성해내는 자연어 생성 모델로 뉴럴 기계번역에 사용되는 이 모델이 \n",
    "\n",
    "텍스트 요약에도 사용될 수 있을지 의문스럽지만, 원문을 요약문으로 번역한다고 생각한다면 이해하기 쉬울것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-discussion",
   "metadata": {},
   "source": [
    "### seq2seq 개요\n",
    "\n",
    "![](https://github.com/MulderKim/EXPLORATION/blob/main/10/etc/E-21-2.max-800x600.png?raw=true)\n",
    "\n",
    "원문을 첫 번째 RNN인 인코더로 입력하면, 인코더는 이를 하나의 고정된 벡터로 변환하는데 이 벡터를 문맥 정보를 가지고 있는 벡터라고 하여 컨텍스트 벡터(context vector)라고 한다. \n",
    "두 번째 RNN인 디코더는 이 컨텍스트 벡터를 전달받아 한 단어씩 생성해내서 요약 문장을 완성한다\n",
    "\n",
    "### LSTM과 컨텍스트 벡터\n",
    "\n",
    "seq2seq를 구현할 때, 인코더/디코더로 바닐라 RNN이 아니라 LSTM을 사용할것이다.\n",
    "![](https://github.com/MulderKim/EXPLORATION/blob/main/10/etc/E-21-3.max-800x600.png?raw=true)\n",
    "\n",
    "LSTM이 바닐라 RNN과 다른 점은 다음 time step의 셀에 hidden state, cell state를 함께 전달한다는 점이다. \n",
    "다시 말해, 인코더가 디코더에 전달하는 컨텍스트 벡터 또한 hidden state h와 cell state c 두 개의 값 모두 존재해야 한다는 뜻이다\n",
    "\n",
    "### 시작 토큰과 종료 토큰\n",
    "\n",
    "![](https://github.com/MulderKim/EXPLORATION/blob/main/10/etc/E-21-4.png?raw=true)\n",
    "\n",
    "seq2seq 구조에서 디코더는 시작 토큰 SOS가 입력되면, 각 시점마다 단어를 생성하고 이 과정을 종료 토큰 EOS를 예측하는 순간까지 멈추지 않기때문에 훈련 데이터의 예측 대상 시퀀스의 앞, 뒤에는 시작 토큰과 종료 토큰을 넣어주는 전처리를 통해 어디서 멈춰야 하는지 알려줄 필요가 있다\n",
    "\n",
    "### 어텐션 메커니즘을 통한 새로운 컨텍스트 벡터 사용하기\n",
    "\n",
    "![](https://github.com/MulderKim/EXPLORATION/blob/main/10/etc/E-21-5.png?raw=true)\n",
    "\n",
    "기존에 배운 seq2seq를 수정하고, 새로운 모듈을 붙여 모델의 성능을 높이기 위해, 기존의 seq2seq는 인코더의 마지막 time step의 hidden state를 컨텍스트 벡터로 사용했다\n",
    "하지만 RNN 계열의 인공 신경망(바닐라 RNN, LSTM, GRU)의 한계로 인해 이 컨텍스트 정보에는 이미 입력 시퀀스의 많은 정보가 손실이 된 상태가 된다.\n",
    "\n",
    "어텐션 메커니즘(Attention Mechanism) 은 이와 달리, 인코더의 모든 step의 hidden state의 정보가 컨텍스트 벡터에 전부 반영되도록 하는 것인데, 인코더의 모든 hidden state가 동일한 비중으로 반영되는 것이 아니라, 디코더의 현재 time step의 예측에 인코더의 각 step이 얼마나 영향을 미치는지에 따른 가중합으로 계산되는 방식이다.\n",
    "\n",
    "위 그림의 예로 들자면, seq2seq 모델이라면 디코더로 전달되는 인코더의 컨텍스트 벡터는 인코더의 마지막 스텝의 hidden state인 h_5h \n",
    "5\n",
    "​\n",
    " 가 되겠지만, 어텐션 메커니즘이 적용된 seq2seq인 Attentional seq2seq이라면 인코더의 컨텍스트 벡터는 예를 들어 0.2h_1h \n",
    "1\n",
    "​\n",
    " +0.3h_2h \n",
    "2\n",
    "​\n",
    " +0.1h_3h \n",
    "3\n",
    "​\n",
    " +0.15h_4h \n",
    "4\n",
    "​\n",
    " +0.25h_5h \n",
    "5\n",
    "​\n",
    "  가 될 수도 있는 것이다.\n",
    "\n",
    "여기서 주의해야 할 것은, 컨텍스트 벡터를 구성하기 위한 인코더 hidden state의 가중치 값은 디코더의 현재 스텝이 어디냐에 따라 계속 달라진다는 점이다.\n",
    "즉, 디코더의 현재 문장 생성 부위가 주어부인지 술어부인지 목적어인지 등에 따라 인코더가 입력 데이터를 해석한 컨텍스트 벡터가 다른 값이 된다는 것이다. \n",
    "이와 달리, 기본적인 seq2seq 모델에서 컨텍스트 벡터는 디코더의 현재 스텝 위치에 무관하게 한번 계산되면 고정값을 가진다.\n",
    "\n",
    "디코더의 현재 스텝에 따라 동적으로 달라지는 인코더의 컨텍스트 벡터를 사용해서 현재의 예측에 활용하면, 디코더가 좀 더 정확한 예측을 할 수 있게 되는데 이러한 Attention 기법은 seq2seq을 비롯하여 향후 다양한 딥러닝 분야를 획기적으로 발전시킨 핵심 개념이 된다. \n",
    "특히 자연어처리 분야에서는 두말할 것도 없겠죠? 아직은 Attention 개념이 명확하게 와닿지 않을지라도, 앞으로도 수차례에 걸쳐 이 개념에 대해 더욱 깊이 있게 다루게 될 것이다.\n",
    "\n",
    "지금까지의 내용을 정리해볼게요.\n",
    "\n",
    "- seq2seq를 사용합니다.\n",
    "- RNN 계열 중 LSTM을 사용하므로 hidden state뿐만 아니라 cell state도 사용해야 합니다.\n",
    "- 디코더의 예측 시퀀스에는 시작 토큰 SOS와 예측 토큰 EOS를 시퀀스의 앞, 뒤로 붙입니다.\n",
    "- seq2seq를 구동시키면 디코더는 시작 토큰을 입력받아 예측을 시작합니다.\n",
    "- seq2seq 기본 모델과 달리, 어텐션 메커니즘을 이용해 인코더의 hidden state의 중요도를 취합한 컨텍스트 벡터를 디코더 스텝별로 계산합니다.\n",
    "- 계산된 컨텍스트 벡터를 이용해서 디코더는 다음 등장할 단어를 예측합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-possibility",
   "metadata": {},
   "source": [
    "## 데이터 준비하기\n",
    "\n",
    "$ mkdir -p ~/aiffel/EXPLORATION/10/news_summarization/data\n",
    "\n",
    "오늘 우리가 텍스트 요약 모델 학습에 사용할 데이터셋은 Kaggle에서 제공된 아마존 리뷰 데이터셋입니다.\n",
    "\n",
    "$ ln -s ~/data/*.csv ~/aiffel/EXPLORATION/10/news_summarization/data\n",
    "\n",
    "이번 실습에서는 NLTK의 불용어(stopwords)를 사용할 예정이며, NTLK와 NLTK 데이터셋이 설치되어 있지 않은 환경이라면 우선 NLTK를 설치하고 NTLK의 데이터셋을 다운로드 진행..\n",
    "\n",
    "NLTK는 Natural Language Toolkit의 축약어로 영어 기호, 통계, 자연어 처리를 위한 라이브러리이다. \n",
    "\n",
    "이 NLTK에는 I, my, me, over, 조사, 접미사와 같이 문장에는 자주 등장하지만, 의미를 분석하고 요약하는 데는 거의 의미가 없는 100여개의 불용어가 미리 정리되어 있어서, 이를 이용해 다운로드한 리뷰 파일에서 불용어를 제거하는 작업을 진행할 예정이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-experience",
   "metadata": {},
   "source": [
    "NLTK 패키지에서 불용어 사전을 다운로드하고, 데이터 전처리를 위한 나머지 패키지도 함께 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "modern-forward",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-concept",
   "metadata": {},
   "source": [
    "링크에서 다운로드 받은 데이터(Reviews.csv)는 총 568,454개의 샘플을 갖고 있는데, 시간상 여기서는 모든 샘플을 사용하지는 않고, 간단히 10만 개의 샘플만 사용해보면.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "appointed-morris",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 100000\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(os.getenv(\"HOME\")+\"/aiffel/EXPLORATION/10/news_summarization/data/Reviews.csv\", nrows=100000)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "drawn-stuart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "illegal-vancouver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35217</th>\n",
       "      <td>I was moved to try this coffee because of othe...</td>\n",
       "      <td>It's Ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36734</th>\n",
       "      <td>This product was horrible.  The very first can...</td>\n",
       "      <td>Awful.  Truly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90042</th>\n",
       "      <td>I love Nature Valley Crunchy Granola Bars and ...</td>\n",
       "      <td>Disappointing for a NV product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89470</th>\n",
       "      <td>I often take some juice and add a bit of seltz...</td>\n",
       "      <td>Nice Taste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37975</th>\n",
       "      <td>We didn't know what the box could be when we a...</td>\n",
       "      <td>Arrived impossibly fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11960</th>\n",
       "      <td>These bite sized banana pieces are delicious. ...</td>\n",
       "      <td>Great Treat - Not Too Sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23753</th>\n",
       "      <td>I really wanted to like these after reading al...</td>\n",
       "      <td>Never tasted cheddar cheese like this!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6176</th>\n",
       "      <td>Not much of a lemon flavor for lemon cookies, ...</td>\n",
       "      <td>Needs more lemon flavor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64274</th>\n",
       "      <td>This is a very difficult tea to find in most s...</td>\n",
       "      <td>Excellent refreshing beverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94414</th>\n",
       "      <td>These chips are just the right size and streng...</td>\n",
       "      <td>Kid Friendly Tortilla Chips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6306</th>\n",
       "      <td>This new flavor is great. Not too spicy as I t...</td>\n",
       "      <td>New Buffalo Ranch Flavor is GREAT!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46529</th>\n",
       "      <td>This tasted so odd. All I can say is it tasted...</td>\n",
       "      <td>Yuck!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92723</th>\n",
       "      <td>These chips are the BEST out there. Period. Lo...</td>\n",
       "      <td>ADDICTING!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53632</th>\n",
       "      <td>The product taste great for a Meal Replacement...</td>\n",
       "      <td>Taste great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31317</th>\n",
       "      <td>Take 5 is a delicious new blend of 5 ingredien...</td>\n",
       "      <td>MMM Good !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  \\\n",
       "35217  I was moved to try this coffee because of othe...   \n",
       "36734  This product was horrible.  The very first can...   \n",
       "90042  I love Nature Valley Crunchy Granola Bars and ...   \n",
       "89470  I often take some juice and add a bit of seltz...   \n",
       "37975  We didn't know what the box could be when we a...   \n",
       "11960  These bite sized banana pieces are delicious. ...   \n",
       "23753  I really wanted to like these after reading al...   \n",
       "6176   Not much of a lemon flavor for lemon cookies, ...   \n",
       "64274  This is a very difficult tea to find in most s...   \n",
       "94414  These chips are just the right size and streng...   \n",
       "6306   This new flavor is great. Not too spicy as I t...   \n",
       "46529  This tasted so odd. All I can say is it tasted...   \n",
       "92723  These chips are the BEST out there. Period. Lo...   \n",
       "53632  The product taste great for a Meal Replacement...   \n",
       "31317  Take 5 is a delicious new blend of 5 ingredien...   \n",
       "\n",
       "                                      Summary  \n",
       "35217                                 It's Ok  \n",
       "36734                          Awful.  Truly.  \n",
       "90042          Disappointing for a NV product  \n",
       "89470                              Nice Taste  \n",
       "37975                 Arrived impossibly fast  \n",
       "11960             Great Treat - Not Too Sweet  \n",
       "23753  Never tasted cheddar cheese like this!  \n",
       "6176                  Needs more lemon flavor  \n",
       "64274           Excellent refreshing beverage  \n",
       "94414             Kid Friendly Tortilla Chips  \n",
       "6306       New Buffalo Ranch Flavor is GREAT!  \n",
       "46529                                   Yuck!  \n",
       "92723                              ADDICTING!  \n",
       "53632                             Taste great  \n",
       "31317                              MMM Good !  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['Text','Summary']]\n",
    "data.head()\n",
    "\n",
    "#랜덤한 15개 샘플 출력\n",
    "data.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-colon",
   "metadata": {},
   "source": [
    "Text 열의 내용을 요약한 것이 Summary 열이며, 인공 신경망을 통해 Text 시퀀스를 입력받으면, Summary 시퀀스를 예측하도록 훈련."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-ghost",
   "metadata": {},
   "source": [
    "## 데이터 전처리하기 (1) 데이터 정리하기\n",
    "\n",
    "### 중복 샘플과 NULL 값이 존재하는 샘플 제거\n",
    "\n",
    "우선 데이터의 중복 샘플 유무를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "egyptian-collaboration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 열에서 중복을 배제한 유일한 샘플의 수 : 88426\n",
      "Summary 열에서 중복을 배제한 유일한 샘플의 수 : 72348\n"
     ]
    }
   ],
   "source": [
    "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['Text'].nunique())\n",
    "print('Summary 열에서 중복을 배제한 유일한 샘플의 수 :', data['Summary'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-professor",
   "metadata": {},
   "source": [
    "데이터프레임의 drop_duplicates()를 사용하면, 손쉽게 중복 샘플을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "later-crash",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88426\n"
     ]
    }
   ],
   "source": [
    "# inplace=True 를 설정하면 DataFrame 타입 값을 return 하지 않고 data 내부를 직접적으로 바꿉니다\n",
    "data.drop_duplicates(subset = ['Text'], inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-wedding",
   "metadata": {},
   "source": [
    ".isnull().sum()을 사용하여 데이터프레임에 Null 값이 있는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "romance-nightmare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text       0\n",
      "Summary    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-texture",
   "metadata": {},
   "source": [
    "데이터프레임에서 Null을 제거할 때는 dropna() 함수를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "quarterly-memory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88425\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-buffer",
   "metadata": {},
   "source": [
    "### 텍스트 정규화와 불용어 제거\n",
    "\n",
    "단어들 중에서는 같은 의미인데도 다른 표현으로 쓰여 마치 다른 단어들처럼 간주되는 경우가 있다. \n",
    "\n",
    "예를 들어서 it'll은 it will과 같고, mustn't과 must not은 사실 같은 표현인데, 이런 경우 기계가 굳이 이들을 마치 다른 단어로 간주하게 해서 연산량을 늘리는 것보다는 기계 학습 전에 미리 같은 표현으로 통일시켜주는 것이 기계의 연산량을 줄일 수 있는 방법이며 이러한 방법론을 텍스트 처리에서는 텍스트 정규화(text normalization) 라고 한다.\n",
    "\n",
    "텍스트 정규화를 위한 사전(dictionary)을 아래와 같이 구성할 거예요. 이 사전은 아래의 링크에서 참고하여 만들었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "outstanding-fraud",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-penetration",
   "metadata": {},
   "source": [
    "일반적으로 텍스트에는 자주 등장하지만 자연어 처리를 할 때 실질적으로 별 도움이 되지 않는 단어들이 존재하는데, 이를 불용어(stopwords)라고 한다. \n",
    "\n",
    "불용어를 제거하는 것이 자연어 처리의 성능을 높이는 방법일 수 있기에, NLTK에서 제공하는 불용어 리스트를 참조해, 샘플에서 불용어를 제거할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "happy-stable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-feeling",
   "metadata": {},
   "source": [
    "NLTK에서 미리 정의하여 제공하고 있는 불용어는 총 179로 이를 사용하여 불용어를 제거한뒤 이 작업 외에도 모든 영어 문자는 소문자로 만들고, \n",
    "\n",
    "섞여있는 html 태그를 제거하고, 정규 표현식을 통해 각종 특수문자를 제거해서 정말 필요한 내용만 잘 학습할 수 있도록 처리.\n",
    "\n",
    "함수의 하단을 보면, NLTK를 이용해 불용어를 제거하는 파트가 있는데, 이는 Text 전처리 시에서만 호출하고 이미 상대적으로 문장 길이가 짧은 \n",
    "\n",
    "Summary 전처리할 때는 호출하지 않고, Abstractive한 문장 요약 결과문이 자연스러운 문장이 되려면 \n",
    "\n",
    "이 불용어들이 Summary에는 남아 있는 게 더 좋을것으로 보여서 처리를 위해서 함수의 인자로 remove_stopwords를 추가하고, if문을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "protective-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-seattle",
   "metadata": {},
   "source": [
    "전처리 전, 후의 결과를 확인하기 위해서 임의의 text와 summary를 만들어 함수를 호출해 볼까요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "significant-toyota",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything bought great infact ordered twice third ordered wasfor mother father\n",
      "great way to start the day\n"
     ]
    }
   ],
   "source": [
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(preprocess_sentence(temp_text))\n",
    "print(preprocess_sentence(temp_summary, False))  # 불용어를 제거하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-moisture",
   "metadata": {},
   "source": [
    "모든 알파벳이 소문자로 변환되고, html 태그가 제거, 괄호로 묶였던 단어 시퀀스가 제거된 것도 확인할 수 있으며, 특수문자가 제거되면서 영어만 남았다.\n",
    "\n",
    "함수가 잘 작동하는 것을 확인했으니, 훈련 데이터 전체에 대해서 전처리를 수행 \n",
    "\n",
    "이때, Text의 경우에는 불용어를 제거하고, Summary의 경우에는 불용어를 제거하지 않을 것이므로 따로 호출해서 진행해야 하기 때때문에, \n",
    "\n",
    "먼저 Text를 전처리하고, 결과를 확인하기 위해서 상위 5개의 줄을 출력\n",
    "\n",
    "❗이 코드는 시간이 오래 걸리므로 아래 멀티프로세싱 코드를 실행하는것을 추천. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "stopped-cabin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better', 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo', 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch', 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal', 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/b007i7yygy/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good quality dog food', 'not as advertised', 'delight says it all', 'cough medicine', 'great taffy']\n"
     ]
    }
   ],
   "source": [
    "clean_text = []\n",
    "# 전체 Text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['Text']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "\n",
    "# 전처리 후 출력\n",
    "print(clean_text[:5])\n",
    "\n",
    "\n",
    "clean_summary = []\n",
    "# 전체 Summary 데이터에 대한 전처리 : 5분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['Summary']:\n",
    "    clean_summary.append(preprocess_sentence(s, False))\n",
    "\n",
    "print(clean_summary[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-virginia",
   "metadata": {},
   "source": [
    "### 🖥️ 잠깐! 멀티프로세싱을 사용해보자.\n",
    "\n",
    "위 코드와 같이 싱글 프로세스로 실행하면 데이터 전처리 하는데 꽤나 많은 시간이 소요됩니다.\n",
    "\n",
    "따라서 멀티프로세싱을 활용하여 별도의 프로세스를 생성하여 병렬처리하면 CPU수에 비례하여 획기적으로 소요 시간을 줄일 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "unexpected-selling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223.29291558265686  seconds\n",
      "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better'\n",
      " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo'\n",
      " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch'\n",
      " ...\n",
      " 'favorite brand korean ramen spicy used eating spicy food make sure use spice pack add egg soup makes great snack'\n",
      " 'like noodles although say spicy somewhat understatement one else family tolerates spicy well seeing looking forward extra little something palate disappointed completely honest usually drain liquid almost much'\n",
      " 'love noodle twice week amazing thing feel well cold hot bowl noodle cure upset stomach headache running nose may work definitely try']\n",
      "5.118485450744629  seconds\n",
      "['good quality dog food' 'not as advertised' 'delight says it all' ...\n",
      " 'great ramen' 'spicy'\n",
      " 'this spicy noodle cures my cold upset stomach and headache every time']\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp   # 멀티 프로세싱으로 전처리 속도를 획기적으로 줄여봅시다\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import time\n",
    "from functools import partial  # map을 할 때 함수에 여러 인자를 넣어줄 수 있도록 합니다\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# num_cores 만큼 쪼개진 데이터를 전처리하여 반환합니다\n",
    "def appendTexts(sentences, remove_stopwords):\n",
    "  texts = []\n",
    "  for s in sentences:\n",
    "    texts += preprocess_sentence(s, remove_stopwords),\n",
    "  return texts\n",
    "\n",
    "def preprocess_data(data, remove_stopwords=True):\n",
    "  start_time = time.time()\n",
    "  num_cores = mp.cpu_count()  # 컴퓨터의 코어 수를 구합니다\n",
    "\n",
    "  text_data_split = np.array_split(data, num_cores)  # 코어 수만큼 데이터를 배분하여 병렬적으로 처리할 수 있게 합니다\n",
    "  pool = Pool(num_cores)\n",
    "\n",
    "  processed_data = np.concatenate(pool.map(partial(appendTexts, remove_stopwords=remove_stopwords), text_data_split))  # 각자 작업한 데이터를 하나로 합쳐줍니다\n",
    "  pool.close()\n",
    "  pool.join()\n",
    "  print(time.time() - start_time, \" seconds\")\n",
    "  return processed_data\n",
    "\n",
    "clean_text = preprocess_data(data['Text'])  # 클라우드 기준으로 3~4분 정도 소요 됩니다\n",
    "print(clean_text)\n",
    "\n",
    "clean_summary = preprocess_data(data['Summary'], remove_stopwords=False) # 클라우드 기준 1분정도 소요됩니다.\n",
    "print(clean_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-kruger",
   "metadata": {},
   "source": [
    "이제 Summary에 대해서 전처리 함수를 호출해 줄 때는, 불용어 제거를 수행하지 않는다는 의미에서 두 번째 인자로 False를 넣어 실행.\n",
    "\n",
    "텍스트 정제의 과정을 거친 후에는 다시 한번 빈(empty) 샘플이 생겼는지 확인해보고, 정제 전에는 데이터가 존재했지만, \n",
    "\n",
    "정제 과정에서 문장의 모든 단어가 사라지는 경우가 있을 수 있어서 이렇게 되면 샘플 자체가 빈 값을 가지게 됨.\n",
    "\n",
    "쉽게 확인하기 위해 데이터들을 데이터프레임에 재저장 하고 빈(empty) 값을 가진 샘플들이 있다면, 모두 Null 값을 가진 샘플로 대체."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "hungry-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Text'] = clean_text\n",
    "data['Summary'] = clean_summary\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "global-excellence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text        0\n",
       "Summary    70\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-queue",
   "metadata": {},
   "source": [
    "Summary 열에서 70개의 Null 값이 생겼는데 원래는 단어가 있었는데, 정제 과정에서 모든 단어가 제거되어 빈 샘플이 70개나 생겼다는 의미로 모두 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "educational-norwegian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88355\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-glucose",
   "metadata": {},
   "source": [
    "## 데이터 전처리하기 (2) 훈련데이터와 테스트데이터 나누기\n",
    "\n",
    "### 샘플의 최대 길이 정하기\n",
    "\n",
    "훈련에 사용할 샘플의 최대 길이를 정해주기 전에 Text와 Summary의 최소, 최대, 평균 길이를 구하고 또한 길이 분포를 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "finished-judge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 2\n",
      "텍스트의 최대 길이 : 1235\n",
      "텍스트의 평균 길이 : 38.792428272310566\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 28\n",
      "요약의 평균 길이 : 4.010729443721352\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['Text']]\n",
    "summary_len = [len(s.split()) for s in data['Summary']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('Summary')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Summary')\n",
    "plt.hist(summary_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-wyoming",
   "metadata": {},
   "source": [
    "많은 양의 데이터를 다룰 때는 데이터를 시각화하여 보는 것이 도움이 된다. \n",
    "\n",
    "위에서부터 차례대로 그래프는 각각 요약과 실제 텍스트의 길이 분포, 요약본 샘플 길이별 개수, 실제 텍스트 샘플 길이별 개수를 나타내고 있다.\n",
    "\n",
    "Text의 경우 최소 길이가 2, 최대 길이가 1,235로 그 차이가 굉장히 크지만만, 평균 길이는 38로 시각화된 그래프로 봤을 때는 \n",
    "\n",
    "대체적으로는 100 내외의 길이를 가진다는 것을 확인할 수 있다.\n",
    "\n",
    "Summary의 경우 최소 길이가 1, 최대 길이가 28, 그리고 평균 길이가 4로 Text에 비해 상대적으로 길이가 매우 짧으며, \n",
    "\n",
    "그래프로 봤을 때에도 대체적으로 10이하의 길이를 가지고 있으며, 이로부터 Text의 최대 길이와 Summary의 적절한 최대 길이를 임의로 정해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "known-julian",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 50\n",
    "summary_max_len = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-manor",
   "metadata": {},
   "source": [
    "각각 50과 8로 정했는데 이 길이를 선택했을 때, 얼마나 많은 샘플들을 자르지 않고 포함할 수 있는지 통계로 확인하는 편이 객관적으로 길이를 결정하는 데 \n",
    "\n",
    "도움이 될기 때문에, 훈련 데이터와 샘플의 길이를 입력하면, 데이터의 몇 %가 해당하는지 계산하는 함수를 만들어서 좀 더 정확하게 판단해보기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "banner-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-testimony",
   "metadata": {},
   "source": [
    "이렇게 만든 함수를 Text와 Summary에 적용해 우리가 결정한 임의의 길이가 몇%의 샘플까지 포함하는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "convinced-edmonton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 50 이하인 샘플의 비율: 0.7745119121724859\n",
      "전체 샘플 중 길이가 8 이하인 샘플의 비율: 0.9424593967517402\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['Text'])\n",
    "below_threshold_len(summary_max_len,  data['Summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-monte",
   "metadata": {},
   "source": [
    "각각 50과 8로 패딩을 하게 되면 해당 길이보다 긴 샘플들은 내용이 잘리게 되는데, Text 열의 경우에는 약 23%의 샘플들이 내용이 손실됨을 확인.\n",
    "\n",
    "우정해진 길이보다 길면 제외하는 방법으로 데이터를 정제."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "public-wireless",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 65818\n"
     ]
    }
   ],
   "source": [
    "data = data[data['Text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['Summary'].apply(lambda x: len(x.split()) <= summary_max_len)]\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-plasma",
   "metadata": {},
   "source": [
    "### 시작 토큰과 종료 토큰 추가하기\n",
    "\n",
    "seq2seq 훈련을 위해서는 디코더의 입력과 레이블에 시작 토큰과 종료 토큰을 추가할 필요가 있기 때문에, 시작 토큰은 sostoken, 종료 토큰은 eostoken으로 앞, 뒤로 추가.\n",
    "\n",
    "디코더의 입력에 해당하면서 시작 토큰이 맨 앞에 있는 문장의 이름을 decoder_input, 디코더의 출력 또는 레이블에 해당되면서 종료 토큰이 맨 뒤에 붙는 문장의 이름을 decoder_target이라고 이름을 정하고 두 개의 문장 모두 Summary 열로부터 만듬.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "harmful-seafood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>good quality dog food</td>\n",
       "      <td>sostoken good quality dog food</td>\n",
       "      <td>good quality dog food eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
       "      <td>not as advertised</td>\n",
       "      <td>sostoken not as advertised</td>\n",
       "      <td>not as advertised eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>delight says it all</td>\n",
       "      <td>sostoken delight says it all</td>\n",
       "      <td>delight says it all eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>cough medicine</td>\n",
       "      <td>sostoken cough medicine</td>\n",
       "      <td>cough medicine eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>great taffy</td>\n",
       "      <td>sostoken great taffy</td>\n",
       "      <td>great taffy eostoken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                Summary  \\\n",
       "0  bought several vitality canned dog food produc...  good quality dog food   \n",
       "1  product arrived labeled jumbo salted peanuts p...      not as advertised   \n",
       "2  confection around centuries light pillowy citr...    delight says it all   \n",
       "3  looking secret ingredient robitussin believe f...         cough medicine   \n",
       "4  great taffy great price wide assortment yummy ...            great taffy   \n",
       "\n",
       "                    decoder_input                  decoder_target  \n",
       "0  sostoken good quality dog food  good quality dog food eostoken  \n",
       "1      sostoken not as advertised      not as advertised eostoken  \n",
       "2    sostoken delight says it all    delight says it all eostoken  \n",
       "3         sostoken cough medicine         cough medicine eostoken  \n",
       "4            sostoken great taffy            great taffy eostoken  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['Summary'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['Summary'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-stroke",
   "metadata": {},
   "source": [
    "인코더의 입력, 디코더의 입력과 레이블을 각각 다시 Numpy 타입으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "answering-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['Text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-armor",
   "metadata": {},
   "source": [
    "훈련 데이터와 테스트 데이터를 분리\n",
    "\n",
    "encoder_input과 크기와 형태가 같은 순서가 섞인 정수 시퀀스를 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "common-internship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21545 60090  5834 ... 52730 51553 49166]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-investigator",
   "metadata": {},
   "source": [
    "정수 시퀀스를 이용해 다시 데이터의 샘플 순서를 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eligible-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-covering",
   "metadata": {},
   "source": [
    "섞인 데이터를 8:2의 비율로 훈련 데이터와 테스트 데이터로 분리, 전체 데이터의 크기에서 0.2를 곱해서 테스트 데이터의 크기를 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acoustic-hazard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 13163\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :', n_of_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-amount",
   "metadata": {},
   "source": [
    "정의한 테스트 데이터의 개수를 이용해 전체 데이터를 양분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "uniform-exclusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 52655\n",
      "훈련 레이블의 개수 : 52655\n",
      "테스트 데이터의 개수 : 13163\n",
      "테스트 레이블의 개수 : 13163\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-noise",
   "metadata": {},
   "source": [
    "## 데이터 전처리하기 (3) 정수 인코딩\n",
    "\n",
    "### 단어 집합(vocabulary) 만들기 및 정수 인코딩\n",
    "\n",
    "기계가 텍스트를 숫자로 처리할 수 있도록 훈련 데이터와 테스트 데이터의 단어들을 모두 정수로 바꿔줘야 하는데, 이를 위해서 각 단어에 고유한 정수를 맵핑하는 작업이 필요. \n",
    "\n",
    "이 과정을 단어 집합(vocabulary) 을 만든다고 표현하고, 원문에 해당되는 encoder_input_train에 대해서 단어 집합을 만듬.\n",
    "\n",
    "Keras의 토크나이저를 사용하면, 입력된 훈련 데이터로부터 단어 집합을 만들 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "crazy-southwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-lighter",
   "metadata": {},
   "source": [
    "이제 단어 집합이 생성되는 동시에 각 단어에 고유한 정수가 부여되어 생성된 단어 집합은 src_tokenizer.word_index에 저장되어 있는데, 이렇게 만든 단어 집합에 있는 모든 단어를 사용하는 것이 아니라, 빈도수가 낮은 단어들은 훈련 데이터에서 제외하고 진행.\n",
    "\n",
    "등장 빈도수가 7회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인.\n",
    "\n",
    "src_tokenizer.word_counts.items()에는 단어와 각 단어의 등장 빈도수가 저장돼 있는데, 이를 통해서 통계적인 정보를 얻을 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "macro-toronto",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 31951\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 23724\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 8227\n",
      "단어 집합에서 희귀 단어의 비율: 74.25119714562925\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.3899359627133037\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-monte",
   "metadata": {},
   "source": [
    "encoder_input_train에는 3만여 개의 단어가 있네요. 그 아래의 통계 정보들을 해석해보면..\n",
    "\n",
    "등장 빈도가 threshold 값인 7회 미만, 즉, 6회 이하인 단어들은 단어 집합에서 무려 70% 이상을 차지하지만, 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 적은 수치인 3.39%밖에 되지 않음.\n",
    "\n",
    "그래서 등장 빈도가 6회 이하인 단어들은 정수 인코딩 과정에서 빼고, 훈련 데이터에서 제거. \n",
    "\n",
    "이를 제외한 단어 집합의 크기를 8천여 개로 계산했는데, 이와 비슷한 값으로 어림잡아 단어 집합의 크기를 8,000으로 제한. \n",
    "\n",
    "토크나이저를 정의할 때 num_words의 값을 정해주면, 단어 집합의 크기를 제한할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "caroline-imagination",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 8000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-terminology",
   "metadata": {},
   "source": [
    "texts_to_sequences()는 생성된 단어 집합에 기반하여 입력으로 주어진 텍스트 데이터의 단어들을 모두 정수로 변환하는 정수 인코딩을 수행. \n",
    "\n",
    "현재 단어 집합의 크기를 8,000으로 제한했으니까 이제 8,000이 넘는 숫자들은 정수 인코딩 후에는 데이터에 존재하지 않음.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "devoted-harvard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24, 450, 450, 360, 63, 535, 149, 286, 30, 1868, 4373, 535], [19, 8, 10, 22, 4270, 155, 22, 187, 1069, 350, 25, 64, 882, 2468, 1554, 21, 94, 44, 391, 21, 335, 157, 3539], [39, 351, 270, 395, 711, 35, 383, 1085]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-roulette",
   "metadata": {},
   "source": [
    "이제 더 이상 텍스트 데이터가 아니라 정수가 나오고 있음을 확인\n",
    "\n",
    "Summary 데이터에 대해서도 동일한 작업을 수행, 케라스의 토크나이저를 사용하여 decoder_input_train을 입력으로 전체 단어 집합과 각 단어에 대한 빈도수를 계산."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "mature-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-translation",
   "metadata": {},
   "source": [
    "이제 단어 집합이 생성되는 동시에 각 단어에 고유한 정수가 부여되었으며, 이는 tar_tokenizer.word_index에 저장되어 있음. tar_tokenizer.word_counts.items()에는 단어와 각 단어의 등장 빈도수가 저장돼 있는데, 이를 통해서 통계적인 정보를 얻어서, 등장 빈도수가 6회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "hundred-scottish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 10479\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 8095\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 2384\n",
      "단어 집합에서 희귀 단어의 비율: 77.24973757037885\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.8817710685332125\n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-guard",
   "metadata": {},
   "source": [
    "등장 빈도가 5회 이하인 단어들은 단어 집합에서 약 77%를 차지하고 있지만, 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 매우 적은 수치인 5.89%밖에 되지 않기 때문에, 아까 했던 것과 동일하게 이 단어들은 모두 제거하면, 어림잡아 2,000을 단어 집합의 크기로 제한."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "exact-wales",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 3, 383, 7, 485, 338], [1, 11, 18, 184, 19, 6, 246], [1, 3, 17, 3, 137], [1, 48], [1, 1370]]\n",
      "target\n",
      "decoder  [[3, 383, 7, 485, 338, 2], [11, 18, 184, 19, 6, 246, 2], [3, 17, 3, 137, 2], [48, 2], [1370, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 2000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-linux",
   "metadata": {},
   "source": [
    "현재 decoder_input_train과 decoder_target_train에는 더 이상 숫자 2,000이 넘는 숫자들은 존재하지 않음. \n",
    "\n",
    "전체 데이터에서 빈도수가 낮은 단어가 삭제되었다는 것은 빈도수가 낮은 단어만으로 구성되었던 샘플들은 이제 빈(empty) 샘플이 되었을 가능성이 있음. \n",
    "\n",
    "길이가 상대적으로 길었던 원문(Text)의 경우에는 문제 없겠지만, 평균 길이가 4밖에 되지 않았던 요약문(Summary)의 경우 이 현상이 굉장히 많이  발생가능.\n",
    "\n",
    "요약문에서 길이가 0이 된 샘플들의 인덱스를 받고, 주의할 점은 요약문인 decoder_input에는 sostoken 또는 decoder_target에는 eostoken이 추가된 상태이고, 이 두 토큰은 모든 샘플에서 등장하므로 빈도수가 샘플 수와 동일하게 매우 높으므로 단어 집합 제한에도 삭제되지 않음. \n",
    "\n",
    "그래서 이제 길이가 0이 된 요약문의 실제 길이는 1로 나오는 이유는 길이 0이 된 decoder_input에는 sostoken, decoder_target에는 eostoken만 남아 있기 때문.\n",
    "\n",
    "훈련 데이터와 테스트 데이터에 대해서 요약문의 길이가 1인 경우의 인덱스를 각각 drop_train과 drop_test에 라는 변수에 저장. 이 샘플들은 모두 삭제."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "coated-swiss",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 1258\n",
      "삭제할 테스트 데이터의 개수 : 356\n",
      "훈련 데이터의 개수 : 51397\n",
      "훈련 레이블의 개수 : 51397\n",
      "테스트 데이터의 개수 : 12807\n",
      "테스트 레이블의 개수 : 12807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-anniversary",
   "metadata": {},
   "source": [
    "### 패딩하기\n",
    "\n",
    "텍스트 시퀀스를 정수 시퀀스로 변환했다면, 이제 서로 다른 길이의 샘플들을 병렬 처리하기 위해 같은 길이로 맞춰주는 패딩 작업을 해줘야하는데,\n",
    "\n",
    "아까 정해두었던 최대 길이로 패딩 하고고, 최대 길이보다 짧은 데이터들은 뒤의 공간에 숫자 0을 넣어 최대 길이로 길이를 맞춤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "sophisticated-privilege",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=summary_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-mexico",
   "metadata": {},
   "source": [
    "전처리 작업은 끝~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-detroit",
   "metadata": {},
   "source": [
    "## 모델 설계하기\n",
    "\n",
    "함수형 API를 이용해서 인코더를 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "conditional-loading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-plane",
   "metadata": {},
   "source": [
    "임베딩 벡터의 차원은 128로 정의하고, hidden state의 크기를 256으로 정의. \n",
    "\n",
    "hidden state는 LSTM에서 얼만큼의 수용력(capacity)를 가질지를 정하는 파라미터로 이 파라미터는 LSTM의 용량의 크기나, LSTM에서의 뉴런의 개수라고 이해하면 되고. 다른 신경망과 마찬가지로, 무조건 용량을 많이 준다고 해서 성능이 반드시 올라가는 것은 아니다.\n",
    "\n",
    "인코더의 LSTM은 총 3개의 층으로 구성해서 모델의 복잡도를 높였는데, hidden state의 크기를 늘리는 것이 LSTM 층 1개의 용량을 늘린다면, 3개의 층을 사용하는 것은 모델의 용량을 늘린다고 볼 수 있으며, 3개의 층을 지나서 인코더로부터 나온 출력 벡터는 디코더로 보내줘야함.\n",
    "\n",
    "디코더를 설계 해보면..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "collected-sociology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-sentence",
   "metadata": {},
   "source": [
    "디코더의 임베딩 층과 LSTM을 설계하는 것은 인코더와 거의 동일하지만 LSTM의 입력을 정의할 때, initial_state의 인자값으로 인코더의 hidden state와 cell state의 값을 넣어줘야 함.\n",
    "\n",
    "디코더의 출력층을 설계해보면면.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "sized-concrete",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      1024000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    256000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 2000)   514000      lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,633,104\n",
      "Trainable params: 3,633,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-scott",
   "metadata": {},
   "source": [
    "디코더의 출력층에서는 Summary의 단어장인 tar_vocab의 수많은 선택지 중 하나의 단어를 선택하는 다중 클래스 분류 문제를 풀어야 하는데, 그렇기 때문에 Dense의 인자로 tar_vocab을 주고, 활성화 함수로 소프트맥스 함수를 사용.\n",
    "\n",
    "인코더의 hidden state와 cell state를 디코더의 초기 state로 사용하는 가장 기본적인 seq2seq를 설계했는데 디코더의 출력층을 설계를 살짝 바꿔서 성능을 높일 수 있는 방법이 어텐션 메커니즘이다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-manchester",
   "metadata": {},
   "source": [
    "### 어텐션 메커니즘\n",
    "\n",
    "어텐션 메커니즘을 수행하는 어텐션 함수를 설계하는 것은 또 다른 새로운 신경망을 설계해야 한다는 뜻인데, 지금은 이미 구현된 어텐션 함수를 가져와서 디코더의 출력층에 어떤 방식으로 결합하는지 학습해보자.\n",
    "\n",
    "깃허브에 공개돼 있는 어텐션 함수를 다운로드."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "funky-intranet",
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-vietnam",
   "metadata": {},
   "source": [
    "attention.py 파일을 다운받은후, 어텐션 메커니즘을 사용할 준비가 되었으니, 설계한 디코더의 출력층을 다음과 같이 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "reserved-machinery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      1024000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    256000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 2000)   1026000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,276,432\n",
      "Trainable params: 4,276,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-alberta",
   "metadata": {},
   "source": [
    "인코더의 hidden state들과 디코더의 hidden state들을 어텐션 함수의 입력으로 사용하고, 어텐션 함수가 리턴한 값을 예측 시에 디코더의 hidden state와 함께 활용하는 형태로 작동하고 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-lyric",
   "metadata": {},
   "source": [
    "## 모델 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "mental-spanking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "201/201 [==============================] - 141s 649ms/step - loss: 3.1382 - val_loss: 2.4054\n",
      "Epoch 2/50\n",
      "201/201 [==============================] - 129s 644ms/step - loss: 2.4068 - val_loss: 2.2889\n",
      "Epoch 3/50\n",
      "201/201 [==============================] - 129s 642ms/step - loss: 2.2739 - val_loss: 2.1613\n",
      "Epoch 4/50\n",
      "201/201 [==============================] - 129s 642ms/step - loss: 2.1429 - val_loss: 2.0788\n",
      "Epoch 5/50\n",
      "201/201 [==============================] - 129s 642ms/step - loss: 2.0628 - val_loss: 2.0115\n",
      "Epoch 6/50\n",
      "201/201 [==============================] - 129s 642ms/step - loss: 1.9841 - val_loss: 1.9694\n",
      "Epoch 7/50\n",
      "201/201 [==============================] - 129s 642ms/step - loss: 1.9163 - val_loss: 1.9393\n",
      "Epoch 8/50\n",
      "201/201 [==============================] - 130s 645ms/step - loss: 1.8752 - val_loss: 1.9197\n",
      "Epoch 9/50\n",
      "201/201 [==============================] - 129s 643ms/step - loss: 1.8345 - val_loss: 1.9005\n",
      "Epoch 10/50\n",
      "201/201 [==============================] - 129s 640ms/step - loss: 1.7955 - val_loss: 1.8859\n",
      "Epoch 11/50\n",
      "201/201 [==============================] - 129s 640ms/step - loss: 1.7669 - val_loss: 1.8760\n",
      "Epoch 12/50\n",
      "201/201 [==============================] - 127s 634ms/step - loss: 1.7265 - val_loss: 1.8660\n",
      "Epoch 13/50\n",
      "201/201 [==============================] - 126s 625ms/step - loss: 1.6962 - val_loss: 1.8576\n",
      "Epoch 14/50\n",
      "201/201 [==============================] - 125s 620ms/step - loss: 1.6737 - val_loss: 1.8557\n",
      "Epoch 15/50\n",
      "201/201 [==============================] - 125s 621ms/step - loss: 1.6438 - val_loss: 1.8467\n",
      "Epoch 16/50\n",
      "201/201 [==============================] - 125s 621ms/step - loss: 1.6156 - val_loss: 1.8482\n",
      "Epoch 17/50\n",
      "201/201 [==============================] - 124s 619ms/step - loss: 1.5909 - val_loss: 1.8455\n",
      "Epoch 18/50\n",
      "201/201 [==============================] - 125s 620ms/step - loss: 1.5678 - val_loss: 1.8418\n",
      "Epoch 19/50\n",
      "201/201 [==============================] - 125s 620ms/step - loss: 1.5420 - val_loss: 1.8413\n",
      "Epoch 20/50\n",
      "201/201 [==============================] - 125s 620ms/step - loss: 1.5229 - val_loss: 1.8427\n",
      "Epoch 21/50\n",
      "201/201 [==============================] - 124s 619ms/step - loss: 1.5066 - val_loss: 1.8503\n",
      "Epoch 00021: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1) # EarlyStopping은 특정 조건이 충족되면 훈련을 멈추는 역할\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[es], epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-macro",
   "metadata": {},
   "source": [
    "val_loss(검증 데이터의 손실)을 관찰하다가, 검증 데이터의 손실이 줄어들지 않고 증가하는 현상이 2회(patience=2) 관측되면 학습을 멈추도록 설정돼 있다.\n",
    "\n",
    "EarlyStopping이 작동한다면 epochs가 아무리 크게 설정되어 있어도 모델 훈련을 최적점에서 멈출 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-lighting",
   "metadata": {},
   "source": [
    "훈련 데이터의 손실과 검증 데이터의 손실이 줄어드는 과정을 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "latest-population",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-child",
   "metadata": {},
   "source": [
    "## 인퍼런스 모델 구현하기\n",
    "\n",
    "테스트 단계에서는 정수 인덱스 행렬로 존재하던 텍스트 데이터를 실제 데이터로 복원해야 하므로, 필요한 3개의 사전을 아래와 같이 미리 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "native-cycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-taylor",
   "metadata": {},
   "source": [
    "seq2seq는 훈련할 때와 실제 동작할 때(인퍼런스 단계)의 방식이 다르므로 그에 맞게 모델 설계를 별개로 진행해야 한다.\n",
    "\n",
    "훈련 단계에서는 디코더의 입력부에 정답이 되는 문장 전체를 한꺼번에 넣고 디코더의 출력과 한 번에 비교할 수 있어서, 인코더와 디코더를 엮은 모델 하나면 되지만\n",
    "\n",
    "정답 문장이 없는 인퍼런스 단계에서는 만들어야 할 문장의 길이만큼 디코더가 반복 구조로 동작해야 하기 때문에 인퍼런스를 위한 모델 설계를 별도로 해주어야 한다. \n",
    "\n",
    "이때는 인코더 모델과 디코더 모델을 분리해서 설계."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "liberal-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-endorsement",
   "metadata": {},
   "source": [
    "어텐션 메커니즘을 사용하는 출력층을 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "spatial-hindu",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-advocate",
   "metadata": {},
   "source": [
    "인퍼런스 단계에서 단어 시퀀스를 완성하는 함수를 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "broadband-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-reasoning",
   "metadata": {},
   "source": [
    "## 모델 테스트하기\n",
    "\n",
    "테스트 단계에서는 정수 시퀀스를 텍스트 시퀀스로 변환하여 결과를 확인하는 것이 편해 주어진 정수 시퀀스를 텍스트 시퀀스로 변환하는 함수를 만듬. \n",
    "\n",
    "함수를 만들 때, Text의 정수 시퀀스에서는 패딩을 위해 사용되는 숫자 0을 제외하고 Summary의 정수 시퀀스에서는 숫자 0, 시작 토큰의 인덱스, 종료 토큰의 인덱스를 출력에서 제외하도록 만듬."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "incident-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if ((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-niagara",
   "metadata": {},
   "source": [
    "테스트 데이터 약 50개의 샘플에 대해서 실제 요약과 예측된 요약을 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "associate-poland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : like potato chips must try different know seems totally crunchy tasty intend get flavors near future \n",
      "실제 요약 : always something new and different \n",
      "예측 요약 :  great chips\n",
      "\n",
      "\n",
      "원문 : go use white tea slight taste odor use anymore may like fine \n",
      "실제 요약 : use \n",
      "예측 요약 :  great tea\n",
      "\n",
      "\n",
      "원문 : satisfied first product less glowing review immediately contacted seller sent new fresher bag coffee much closer remember try sweetened condensed milk suggested served way jamaica coco bread go thank prompt service \n",
      "실제 요약 : seller \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : even like cashews combined rest ingredients heavenly combination amazon offer sounds pretty sweet month boxes excellent unique candy \n",
      "실제 요약 : absolutely amazing \n",
      "예측 요약 :  sweet\n",
      "\n",
      "\n",
      "원문 : never reviews read time case needed let buyers mom hershey syrup bitter taste bitter pill know sugar free really come taste like sugar free hey bought pack much faith would good sits pantry try figure friends like least give lol \n",
      "실제 요약 : this is not your mom hershey \n",
      "예측 요약 :  tastes like\n",
      "\n",
      "\n",
      "원문 : used order product per box cans turned dollars double nowhere \n",
      "실제 요약 : what happened to the price \n",
      "예측 요약 :  not what expected\n",
      "\n",
      "\n",
      "원문 : love product best taste texture nutrition natural bar started regular monthly shipment cases amazon first shipment arrived chocolate melted real pain eat amazon fault kind even putting fridge harden coating receive next shipment week let know shipping problem \n",
      "실제 요약 : product melted shipping \n",
      "예측 요약 :  delicious\n",
      "\n",
      "\n",
      "원문 : item recommended bill good tip tasty fast good \n",
      "실제 요약 : popchips \n",
      "예측 요약 :  good stuff\n",
      "\n",
      "\n",
      "원문 : love chocolate found one best cookie real chocolate chunks every bit dream trust im real chocolate lover one black diamond read somebody said cheap product cookies super \n",
      "실제 요약 : yumm \n",
      "예측 요약 :  chocolate\n",
      "\n",
      "\n",
      "원문 : jack link beef steak peppered always nice pocket case get bit hungry \n",
      "실제 요약 : good snack \n",
      "예측 요약 :  great jerky\n",
      "\n",
      "\n",
      "원문 : thought would similar taste another brand carbonated juice market called izze fewer calories tastes better costs less however switch weird artificial aftertaste tastes like blend orange juice orange soda good way also calories per serving grams sugar might well drink soda beverage healthier certainly cheaper \n",
      "실제 요약 : not for me \n",
      "예측 요약 :  too sweet for me\n",
      "\n",
      "\n",
      "원문 : kids love snacks loved variety buying bulk nice different flavors package \n",
      "실제 요약 : great snack \n",
      "예측 요약 :  great snack\n",
      "\n",
      "\n",
      "원문 : come england cannot without salad cream cheapest place buy lot cheaper supermarket chain \n",
      "실제 요약 : price \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : like switch foods dog hand mornings short time wonderful dog really likes serving fast mess \n",
      "실제 요약 : handy dog food \n",
      "예측 요약 :  dog loves it\n",
      "\n",
      "\n",
      "원문 : great find warehouse deals concerned would receive week til expired full months ahead exp date household devoured \n",
      "실제 요약 : great purchase \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : chips good potato chip might find taste wise even better guilt healthy \n",
      "실제 요약 : excellent taste healthy too \n",
      "예측 요약 :  great chips\n",
      "\n",
      "\n",
      "원문 : perfect snack drop breakfast lunch creamy without sweet glad amazon offers bar since grocery stores area discontinued give try \n",
      "실제 요약 : my am daily snack \n",
      "예측 요약 :  delicious\n",
      "\n",
      "\n",
      "원문 : love ordering amazon orders arrive fast well packed however smokehouse natural chicken breast strips supposed made usa paid afraid buy made china dog sick even gave small piece everyday would throw never kitchen train made china also supposed lean fat pieces scrape know wrong \n",
      "실제 요약 : very unhappy \n",
      "예측 요약 :  made in china\n",
      "\n",
      "\n",
      "원문 : good cannot believe actually healthy hey filling bars though \n",
      "실제 요약 : love these \n",
      "예측 요약 :  great snack\n",
      "\n",
      "\n",
      "원문 : dogs like flavors tried dog food reason itching increased tried lamb rice itchy dogs giving limited ingredient dog food try help duck sweet potato cut itching significantly tried lamb rice started itching like natural balance quality ingredients \n",
      "실제 요약 : natural balance lamb and rice \n",
      "예측 요약 :  my dogs love this\n",
      "\n",
      "\n",
      "원문 : wasted money product opened box soon arrived sampled bar stale coating chalky going back buying pure protein bars \n",
      "실제 요약 : arrived stale and \n",
      "예측 요약 :  stale\n",
      "\n",
      "\n",
      "원문 : easy prepare pour powder cup add hot water ginger taste strong spicy minimal lemon flavor taste add water dilute brew make less strong \n",
      "실제 요약 : quite hot may need to \n",
      "예측 요약 :  nice flavor\n",
      "\n",
      "\n",
      "원문 : tried good mix add chocolate chips chewy moist \n",
      "실제 요약 : very tasty \n",
      "예측 요약 :  great chips\n",
      "\n",
      "\n",
      "원문 : toddler yo daughter love delicious little pricey worth right little guy really eat real fruits veggies subscribe save price best found \n",
      "실제 요약 : we all love this \n",
      "예측 요약 :  my favorite\n",
      "\n",
      "\n",
      "원문 : taste slightly sweet buttery nutty must pointed oat organic healthy ages soak water boiling hours overnight cook min perfectly right grateful farmers seller best product diet \n",
      "실제 요약 : great oat \n",
      "예측 요약 :  great tasting and healthy\n",
      "\n",
      "\n",
      "원문 : best jarred pasta sauce ever tasted strong olive flavor enjoyed immensely \n",
      "실제 요약 : fabulous \n",
      "예측 요약 :  best gluten free pasta\n",
      "\n",
      "\n",
      "원문 : jumbo dates excellent love dates tried many different kinds brands local stores internet definitely best also fast delivery received dates business days order date \n",
      "실제 요약 : dates are fantastic \n",
      "예측 요약 :  love this stuff\n",
      "\n",
      "\n",
      "원문 : successfully feeding cats months comparing brand similar brand category would say exceeds expectations high priced blue buffalo indoor cat dry food chicken brown rice recipe pound bag one dollars pound reasonable middle road cat food price cheap cat food said wife extremely satisfied purchase \n",
      "실제 요약 : good life recipe formula works great \n",
      "예측 요약 :  my cats love it\n",
      "\n",
      "\n",
      "원문 : love cookie mix add handful pecans like gluten filled pecan used eat easy make good \n",
      "실제 요약 : good cookies \n",
      "예측 요약 :  delicious\n",
      "\n",
      "\n",
      "원문 : found shampoo nice nothing exceptional like clean smell rinse clean increase volume anything run home would buy fact rinse clean leave residue behind \n",
      "실제 요약 : nice \n",
      "예측 요약 :  works great\n",
      "\n",
      "\n",
      "원문 : oatmeal hit miss oatmeal liked far like much fact easy make cheap buy healthier substitute sugary cereals throw raisins blueberries break texture enjoy good prices \n",
      "실제 요약 : good start to the day \n",
      "예측 요약 :  great cereal\n",
      "\n",
      "\n",
      "원문 : coffee great value bold coffee knock brain time shipping unbelievably fast great transaction \n",
      "실제 요약 : green coffee rocks \n",
      "예측 요약 :  great coffee\n",
      "\n",
      "\n",
      "원문 : raisins taste good lot raisins last long time subscribe save items home starting look like warehouse mind healthy nutritious foods around family \n",
      "실제 요약 : organic food just tastes better \n",
      "예측 요약 :  great cereal\n",
      "\n",
      "\n",
      "원문 : flavor expecting ok super hurry options taste flour noodles kind odd rather small portion spice garlic ginger half bad \n",
      "실제 요약 : well \n",
      "예측 요약 :  not bad\n",
      "\n",
      "\n",
      "원문 : disappointed product eligible return items received outdated use date even order seller sent product seen beyond best date least weeks processed order \n",
      "실제 요약 : received product \n",
      "예측 요약 :  product\n",
      "\n",
      "\n",
      "원문 : used noodles make pad thai also gluten free substitute happy result price good however prefer annie chun brown rice noodle pad thai ounce also gluten free four times fiber quick easy prepare also expensive purchased online though always buy amazon \n",
      "실제 요약 : pretty good gluten free substitute for too \n",
      "예측 요약 :  great substitute for gluten free baking\n",
      "\n",
      "\n",
      "원문 : good buy sure want make sure let sit get much flavor would give taste could light side probably one decaf love product \n",
      "실제 요약 : good buy \n",
      "예측 요약 :  good flavor\n",
      "\n",
      "\n",
      "원문 : little love brand nice know turn nose \n",
      "실제 요약 : toy best meal \n",
      "예측 요약 :  great\n",
      "\n",
      "\n",
      "원문 : product greatest taste like coconut water hard product find purchased try liking tolerable cold really cold tried coconut water warm see really tastes bad like reviews said sure enough right \n",
      "실제 요약 : not the greatest \n",
      "예측 요약 :  not bad\n",
      "\n",
      "\n",
      "원문 : tried quite good novelty regular almonds quality quite high nuts newly opened package fresh crisp texture good taste people try three said liked two said would buy grocery would also buy people tried response negative much green packaging affect flavor served dark \n",
      "실제 요약 : cocoa almonds \n",
      "예측 요약 :  great nuts\n",
      "\n",
      "\n",
      "원문 : bought product review saying product france product china stated label sampled product yet disappointed fault amazon reviewer maybe europe get product france product says packed american roland food new york ingredients listed \n",
      "실제 요약 : product of china very disappointed \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 요약 :  not as advertised\n",
      "\n",
      "\n",
      "원문 : ordered stick looking something little natural could feel good using like certified organic feel like digesting harmful unnecessary chemicals every time lick lips nice mild taste goes really silky \n",
      "실제 요약 : good stuff \n",
      "예측 요약 :  tastes like\n",
      "\n",
      "\n",
      "원문 : like single serve less expensive eco friendly love coffee people donut shop cup hoping would good alternative like flavor seems bitter odd aftertaste blech \n",
      "실제 요약 : not so great \n",
      "예측 요약 :  not bad\n",
      "\n",
      "\n",
      "원문 : policy use non gmo products possible cannot guarantee product produced non gmo corn low prices majority corn produced us gmo assume gmo product great amazon return policy food items stuck \n",
      "실제 요약 : warning they use corn for this product \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : best snacks kids adults love alike added refined sugar take road send school pack take work love \n",
      "실제 요약 : awesome snacks from amazon tasty brand organic snacks \n",
      "예측 요약 :  great snack\n",
      "\n",
      "\n",
      "원문 : opportunity try product free say really taste like banana bread pretty good go snack favorite like homemade goodies preservatives still great snack item pretty tasty \n",
      "실제 요약 : tastes like banana bread \n",
      "예측 요약 :  great snack\n",
      "\n",
      "\n",
      "원문 : always used stick ton bag whenever would go candy shop mall amazing haribo version good interesting taste interesting texture well flavour fruity tropical way pretty chewy soft smooth chewy texture top slightly softer bottom always like \n",
      "실제 요약 : my favourite since was little \n",
      "예측 요약 :  delicious\n",
      "\n",
      "\n",
      "원문 : drunk years find stores good thing found web really enjoy tea everyone shared likes good sweetened refreshing cold comforting hot \n",
      "실제 요약 : love this stuff \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : love dark chocolate fact prefer sweeter milk chocolate perfectly satisfactory bar dark chocolate stand exceptional way disappointed writing price listed product guess based organic nature product going priced average size chocolate bar would make expensive would willing pay product really average quality \n",
      "실제 요약 : an average bar of chocolate \n",
      "예측 요약 :  chocolate\n",
      "\n",
      "\n",
      "원문 : husband eating since college years later still love usually get asian supermarket price actually better amazon love spicy stuff love eat things spicy make put half spice package yummy \n",
      "실제 요약 : great yummy noodles you cannot go wrong \n",
      "예측 요약 :  best mustard\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-designer",
   "metadata": {},
   "source": [
    "많은 결과가 출력이 되는데, 기존의 요약과는 다른 요약을 출력하면서도 원문의 내용을 담고 있는 의미 있는 요약들이 보이며, 일부 요약의 경우에는 원문에 없던 단어를 사용해서 요약을 하는것을 확인할 수 있다. \n",
    "\n",
    "워드 임베딩과 RNN의 콜라보로 이뤄낸 신기한 성과이지만.. 그다지 좋지 않은 요약의 예도 발견할 수 있다. \n",
    "\n",
    "성능을 개선하기 위해서는 seq2seq와 어텐션의 자체의 조합을 좀 더 좋게 수정하는 방법도 있고, 빔 서치(beam search), 사전 훈련된 워드 임베딩(pre-trained word embedding), 또는 인코더 - 디코더 자체의 구조를 새로이 변경한 하는 트랜스포머(Transformer)와 같은 여러 개선 방안들이 존재한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-bailey",
   "metadata": {},
   "source": [
    "## 추출적 요약 해보기\n",
    "\n",
    "텍스트 요약에는 추상적 요약 외에도 이미 본문에 존재하는 단어구, 문장을 뽑아서 요약으로 삼는 추출적 요약 방법도 있다.\n",
    "\n",
    "패키지 Summa에서는 추출적 요약을 위한 모듈인 summarize를 제공하고 있어 아주 간단하게 실습을 해볼 수 있다. \n",
    "\n",
    "영화 매트릭스 시놉시스를 요약해보면서 summarize 사용법을 익혀보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-condition",
   "metadata": {},
   "source": [
    "### 패키지 설치\n",
    "\n",
    "클라우드의 경우 이미 summa 가 설치돼있으니 확인해보고 싶으시면 실행해보자.\n",
    "\n",
    "$ pip list | grep summa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-tracy",
   "metadata": {},
   "source": [
    "### 데이터 다운로드하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "interesting-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-plenty",
   "metadata": {},
   "source": [
    "매트릭스 시놉시스를 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "geological-artwork",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = requests.get('http://rare-technologies.com/the_matrix_synopsis.txt').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "proprietary-magnitude",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The screen is filled with green, cascading code which gives way to the title, The Matrix.\r\n",
      "\r\n",
      "A phone rings and text appears on the screen: \"Call trans opt: received. 2-19-98 13:24:18 REC: Log>\" As a conversation takes place between Trinity (Carrie-Anne Moss) and Cypher (Joe Pantoliano), two free humans, a table of random green numbers are being scanned and individual numbers selected, creating a series of digits not unlike an ordinary phone number, as if a code is being deciphered or a call is being traced.\r\n",
      "\r\n",
      "Trinity discusses some unknown person. Cypher taunts Trinity, suggesting she enjoys watching him. Trinity counters that \"Morpheus (Laurence Fishburne) says he may be 'the One',\" just as the sound of a number being selected alerts Trinity that someone may be tracing their call. She ends the call.\r\n",
      "\r\n",
      "Armed policemen move down a darkened, decrepit hallway in the Heart O' the City Hotel, their flashlight beam bouncing just ahead of them. They come to room 303, kick down the door and find a woman dressed in black, facing away from them. It's Trinity. She brings her hands up from the laptop she's working on at their command.\r\n",
      "\r\n",
      "Outside the hotel a car drives up and three agents appear in neatly pressed black suits. They are Agent Smith (Hugo Weaving), Agent Brown (Paul Goddard), and Agent Jones (Robert Taylor). Agent Smith and the presiding police lieutenant argue. Agent Smith admonishes the policeman that they were given specific orders to contact the agents first, for their\n"
     ]
    }
   ],
   "source": [
    "print(text[:1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-cleaner",
   "metadata": {},
   "source": [
    "### summarize 사용하기\n",
    "\n",
    "Summa의 summarize()의 인자로 사용되는 값\n",
    "\n",
    "---\n",
    "\n",
    "- text (str) : 요약할 테스트.\n",
    "- ratio (float, optional) – 요약문에서 원본에서 선택되는 문장 비율. 0~1 사이값\n",
    "- words (int or None, optional) – 출력에 포함할 단어 수. (만약, ratio와 함께 두 파라미터가 모두 제공되는 경우 ratio는 무시한다.)\n",
    "- split (bool, optional) – True면 문장 list / False는 조인(join)된 문자열을 반환\n",
    "\n",
    "Summa의 summarize는 문장 토큰화를 별도로 하지 않더라도 내부적으로 문장 토큰화를 수행하기 때문에 문장 구분이 되지 않은 원문을 바로 입력으로 넣을 수 있다. \n",
    "\n",
    "비율을 적게 주어서 요약문으로 선택되는 문장의 개수를 줄여기. 원문의 0.005%만을 출력하도록 설정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "electronic-rubber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-freight",
   "metadata": {},
   "source": [
    "만약 리스트로 출력 결과를 받고 싶다면 split 인자의 값을 True로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "paperback-anger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "['Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.', 'Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.']\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005, split=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-engagement",
   "metadata": {},
   "source": [
    "단어의 수로 요약문의 크기를 조절할 수도 있어요. 단어를 50개만 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "choice-summer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Trinity takes Neo to Morpheus.\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, words=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-curve",
   "metadata": {},
   "source": [
    "## 프로젝트: 뉴스기사 요약해보기\n",
    "\n",
    "### 데이터 수집하기\n",
    "\n",
    "데이터는 뉴스 기사 데이터(news_summary_more.csv)를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "average-devices",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "gorgeous-divorce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57381</th>\n",
       "      <td>Infosys must apologise to Murthy for abusing h...</td>\n",
       "      <td>Infosys' ex-CFO Mohandas Pai said Infosys must...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56689</th>\n",
       "      <td>Minor kills self hours after marrying widowed ...</td>\n",
       "      <td>A 15-year-old boy committed suicide two hours ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27046</th>\n",
       "      <td>Swara slams Union Minister for garlanding lync...</td>\n",
       "      <td>Actress Swara Bhasker has slammed Union Minist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81241</th>\n",
       "      <td>Swaraj's husband responds to user asking about...</td>\n",
       "      <td>A Twitter user asked Sushma Swaraj's husband S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63398</th>\n",
       "      <td>50 pregnant women fall ill after antibiotic in...</td>\n",
       "      <td>Over 50 pregnant women and a few new mothers f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29357</th>\n",
       "      <td>Pair of melons auctioned for record Ã¢ÂÂ¹20 l...</td>\n",
       "      <td>A pair of Yubari melons was auctioned at a who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60909</th>\n",
       "      <td>Restaurants to charge 5% GST starting today</td>\n",
       "      <td>Eating out at restaurants is set to get cheape...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12476</th>\n",
       "      <td>Google asked to stop removing Portuguese app s...</td>\n",
       "      <td>Portuguese app store Aptoide has said that a l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34397</th>\n",
       "      <td>Prez approves seizure of fugitive economic off...</td>\n",
       "      <td>President Ram Nath Kovind on Sunday promulgate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37707</th>\n",
       "      <td>Hope you take job you weren't forced into: She...</td>\n",
       "      <td>On the occasion of Congress President Rahul Ga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "57381  Infosys must apologise to Murthy for abusing h...   \n",
       "56689  Minor kills self hours after marrying widowed ...   \n",
       "27046  Swara slams Union Minister for garlanding lync...   \n",
       "81241  Swaraj's husband responds to user asking about...   \n",
       "63398  50 pregnant women fall ill after antibiotic in...   \n",
       "29357  Pair of melons auctioned for record Ã¢ÂÂ¹20 l...   \n",
       "60909        Restaurants to charge 5% GST starting today   \n",
       "12476  Google asked to stop removing Portuguese app s...   \n",
       "34397  Prez approves seizure of fugitive economic off...   \n",
       "37707  Hope you take job you weren't forced into: She...   \n",
       "\n",
       "                                                    text  \n",
       "57381  Infosys' ex-CFO Mohandas Pai said Infosys must...  \n",
       "56689  A 15-year-old boy committed suicide two hours ...  \n",
       "27046  Actress Swara Bhasker has slammed Union Minist...  \n",
       "81241  A Twitter user asked Sushma Swaraj's husband S...  \n",
       "63398  Over 50 pregnant women and a few new mothers f...  \n",
       "29357  A pair of Yubari melons was auctioned at a who...  \n",
       "60909  Eating out at restaurants is set to get cheape...  \n",
       "12476  Portuguese app store Aptoide has said that a l...  \n",
       "34397  President Ram Nath Kovind on Sunday promulgate...  \n",
       "37707  On the occasion of Congress President Rahul Ga...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-hostel",
   "metadata": {},
   "source": [
    "이 데이터는 기사의 본문에 해당되는 text와 headlines 두 가지 열로 구성되어져 있습니다.\n",
    "\n",
    "추상적 요약을 하는 경우에는 text를 본문, headlines를 이미 요약된 데이터로 삼아서 모델을 학습할 수 있다. \n",
    "\n",
    "추출적 요약을 하는 경우에는 오직 text열만을 사용."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-disney",
   "metadata": {},
   "source": [
    "### 데이터 전처리하기 (추상적 요약)\n",
    "\n",
    "실습에서 사용된 전처리를 참고하여 각자 필요하다고 생각하는 전처리를 추가 사용하여 텍스트를 정규화 또는 정제해 보고, \n",
    "\n",
    "불용어 제거를 선택한다면 상대적으로 길이가 짧은 요약 데이터에 대해서도 불용어를 제거하는 것이 좋을지 고민해 보기\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-capture",
   "metadata": {},
   "source": [
    "필요한 라이브러리 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bigger-finding",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: NLTK in /opt/conda/lib/python3.7/site-packages (3.5)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from NLTK) (1.0.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from NLTK) (7.1.2)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from NLTK) (2020.11.13)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from NLTK) (4.56.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install NLTK\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from attention import AttentionLayer\n",
    "from summa.summarizer import summarize\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-contact",
   "metadata": {},
   "source": [
    "중복 확인 및 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "recovered-fountain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98401\n",
      "98280\n",
      "98360\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(data['headlines'].nunique()) #headlines 열에서 중복을 배제한 유일한 샘플의 수\n",
    "print(data['text'].nunique())  # text 열에서 중복을 배제한 유일한 샘플의 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "average-refrigerator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 샘플 제거후 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(subset = ['text'], inplace = True) # 데이터프레임의 drop_duplicates()를 사용하여, 중복 샘플제거\n",
    "print('중복 샘플 제거후 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "processed-union",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum()) #null 값 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-still",
   "metadata": {},
   "source": [
    "텍스트 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "married-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "reliable-effect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "light-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = ['but', 'no', 'not', 'nor', 'only', 'while', 'before', 'after', 'under', \\\n",
    "            'again', 'further']\n",
    "\n",
    "my_stopwords = list(\n",
    "                    filter(lambda word: word not in selection,\n",
    "                        stopwords.words('english')\n",
    "                        )\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "negative-accident",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 168\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'if', 'or', 'because', 'as', 'until', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('불용어 개수 :', len(my_stopwords))\n",
    "print(my_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "seven-explanation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower()    #소문자로...\n",
    "    sentence = BeautifulSoup(sentence, 'lxml').text   #html 태그  제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence)   \n",
    "    sentence = re.sub('\"','', sentence)   \n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) #약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\", \"\",sentence)  # 소유격 제거\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence)  # 영어 외 문자는 공백으로 처리\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence)  # m 3개 이상 -> 2개로 변경\n",
    "    \n",
    "    if remove_stopwords: #불용어 제거 text \n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in my_stopwords if len(word) > 1)\n",
    "    else:           # 불용어 미제거 Summary\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "persistent-denmark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything bought great infact ordered twice third ordered wasfor mother father\n",
      "great way to start the day\n"
     ]
    }
   ],
   "source": [
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(preprocess_sentence(temp_text))\n",
    "print(preprocess_sentence(temp_summary, False))  # 불용어를 제거하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-briefing",
   "metadata": {},
   "source": [
    "멀티 프로세싱으로 전처리 속도 올리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "assisted-procedure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.013509511947632  seconds\n",
      "['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers'\n",
      " 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward after spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit'\n",
      " 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match under rohit sharma captaincy after consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history'\n",
      " ...\n",
      " 'according reports new version science fiction film matrix development michael jordan reportedly play lead role film screenwriter zak penn talks write script film reports added actor keanu reeves starred original film followed two sequels'\n",
      " 'new music video shows rapper snoop dogg aiming toy gun clown character parodying us president donald trump video also shows tv airing news conference headline ronald klump wants deport doggs airing live clown house video remixed version song lavender'\n",
      " 'madhesi morcha alliance seven political parties withdrawn support pm pushpa kamal dahal led nepal government after failed meet seven day ultimatum fulfil demands including endorsement revised constitution amendment bill morcha seats parliament but despite withdrawal support no immediate threat government']\n",
      "5.967089891433716  seconds\n",
      "['upgrad learner switches to career in ml al with salary hike'\n",
      " 'delhi techie wins free food from swiggy for one year on cred'\n",
      " 'new zealand end rohit sharma led india match winning streak' ...\n",
      " 'the matrix film to get reboot reports'\n",
      " 'snoop dogg aims gun at clown dressed as trump in new video'\n",
      " 'madhesi morcha withdraws support to nepalese government']\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp   \n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import time\n",
    "from functools import partial  # map을 할 때 함수에 여러 인자를 넣어줄 수 있도록 한다\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# num_cores 만큼 쪼개진 데이터를 전처리하여 반환한다.\n",
    "def appendTexts(sentences, remove_stopwords):\n",
    "  texts = []\n",
    "  for s in sentences:\n",
    "    texts += preprocess_sentence(s, remove_stopwords),\n",
    "  return texts\n",
    "\n",
    "def preprocess_data(data, remove_stopwords=True):\n",
    "  start_time = time.time()\n",
    "  # 컴퓨터의 코어 수를 구하기\n",
    "  num_cores = mp.cpu_count()  \n",
    "\n",
    "  text_data_split = np.array_split(data, num_cores)  # 코어 수만큼 데이터를 배분하여 병렬적으로 처리할 수 있게 합니다\n",
    "  pool = Pool(num_cores)\n",
    "\n",
    "  processed_data = np.concatenate(pool.map(partial(appendTexts, remove_stopwords=remove_stopwords), text_data_split))  # 각자 작업한 데이터를 하나로 합쳐줍니다\n",
    "  pool.close()\n",
    "  pool.join()\n",
    "  print(time.time() - start_time, \" seconds\")\n",
    "  return processed_data\n",
    "\n",
    "clean_text = preprocess_data(data['text'])  # 클라우드 기준으로 3~4분 정도 소요 됩니다\n",
    "print(clean_text)\n",
    "\n",
    "clean_headlines = preprocess_data(data['headlines'], remove_stopwords=False) # 클라우드 기준 1분정도 소요됩니다.\n",
    "print(clean_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "sound-trail",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_headlines\n",
    "\n",
    "data.replace('', np.nan, inplace=True)\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-termination",
   "metadata": {},
   "source": [
    "훈련데이터와 테스트데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "durable-vampire",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 61\n",
      "텍스트의 평균 길이 : 36.091744611630745\n",
      "제목의 최소 길이 : 1\n",
      "제목의 최대 길이 : 16\n",
      "제목의 평균 길이 : 9.299532330215534\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAeuUlEQVR4nO3de7xXdZ3v8dc7UDNDwSQPcnFj0gVNUbdKJ+toJuLlhM4x0y6imXTRtDnmhNVJs5zoVNrYxcSRgcokxzSZpJBjmDmlAkpyMQ87xIBQTK7qRIKf+WN997j68dubxWL/bu738/FYj99an3X7/IDNZ6/1/a7vUkRgZmZWxqsanYCZmbUuFxEzMyvNRcTMzEpzETEzs9JcRMzMrDQXETMzK81FxKwLkpZLeneNz9EmKST1Tcv3SvpImv+ApLtreX6zneUiYtakIuLmiBjT6DzMuuMiYmZmpbmImHVvlKRHJW2Q9GNJrwaQdKqkBZLWS/qNpEM6d5A0UdIfJG2StETS6bl1fSR9XdKfJS0DTunqxJLOlXR/bjkkfUzS0nTe70hSbv2HJT0maZ2kWZL2T3FJulbSGkkbJS2UdHAP/zlZL+UiYta9M4GxwHDgEOBcSYcBU4CPAq8DbgBmSNot7fMH4B3AXsAXgR9KGpTWXQCcChwGtANn7GA+pwJHplzOBE4EkDQO+Czwd8BA4NfALWmfMcA7gTemnM4Ent3B85pV5SJi1r3rIuJPEbEW+DdgFDABuCEiHoyIrRExDdgMjAaIiH9N+7wUET8GlgJHpeOdCXwzIlakY35lB/OZFBHrI+KPwJyUD8DHgK9ExGMRsQX4R7KrqP2BF4F+wJsBpW1Wl/nDMKvkImLWvady8y8ArwX2By5Nt5TWS1oPDAX2A5B0Tu5W13rgYGCfdIz9gBW5Yz7ZA/mQcvqn3DnXAgIGR8QvgW8D3wHWSJosac8dPK9ZVS4iZjtuBXB1RPTPTa+JiFvSb/43AhcBr4uI/sAisv/QAVaTFZxOw3owp49W5LR7RPwGICKui4gjgJFkt7Uu66HzWi/nImK2424EPibp6NRovYekUyT1A/YAAngGQNJ5ZFcinW4FLpY0RNIAYGIP5fQ94HJJB6Xz7iXpvWn+yJTrLsDzwF+Al3rovNbLuYiY7aCImEfWQP5tYB3QAZyb1i0BvgH8FngaeCvw77ndbwRmAb8DHgZu76Gc7gC+CkyXtJHs6uektHrPdN51ZLfPngW+1hPnNZNfSmVmZmX5SsTMzEpzETEzs9JqVkQkvVrSQ5J+J2mxpC+m+HBJD0rqSE8A75riu6XljrS+LXesy1P8cUkn5uJjU6xDUk81UJqZWUG1vBLZDLwrIg4leyBqrKTRZI1/10bEgWQNfeen7c8H1qX4tWk7JI0EzgIOInty+Ltp6Ig+ZP3eTyLrtnh22tbMzOqkb60OHFmL/XNpcZc0BfAu4P0pPg24ErgeGJfmAW4Dvp3GBRoHTI+IzcATkjp4+enfjohYBiBpetp2SXd57bPPPtHW1raT387MrHeZP3/+nyNiYGW8ZkUEssHmgPnAgWRXDX8A1qdhGQBWAoPT/GDSk7wRsUXSBrJxiQYDD+QOm99nRUX86C7ymEA2VAXDhg1j3rx5O/fFzMx6GUlVR1eoacN6GldoFDCE7OrhzbU8Xzd5TI6I9ohoHzhwm0JqZmYl1aV3VkSsJxss7m1A/863uJEVl1VpfhVpOIi0fi+yh6L+K16xT1dxMzOrk1r2zhooqX+a3x04AXiMrJh0Dn89Hrgzzc9Iy6T1v0ztKjOAs1LvreHACOAhYC4wIvX22pWs8X1Grb6PmZltq5ZtIoOAaald5FXArRHxM0lLyIZm+DLwCHBT2v4m4Aep4XwtWVEgIhZLupWswXwLcGFEbAWQdBHZEBJ9gCkRsbiG38fMzCr0umFP2tvbww3rZmY7RtL8iGivjPuJdTMzK81FxMzMSnMRMTOz0lxEzMystJo+sW5mPadt4l1drls+6ZQ6ZmL2Ml+JmJlZaS4iZmZWmouImZmV5iJiZmaluYiYmVlpLiJmZlaai4iZmZXmImJmZqW5iJiZWWkuImZmVpqLiJmZleYiYmZmpbmImJlZaS4iZmZWmouImZmV5iJiZmaluYiYmVlpLiJmZlaai4iZmZXmImJmZqW5iJiZWWkuImZmVlrNioikoZLmSFoiabGkS1L8SkmrJC1I08m5fS6X1CHpcUkn5uJjU6xD0sRcfLikB1P8x5J2rdX3MTOzbdXySmQLcGlEjARGAxdKGpnWXRsRo9I0EyCtOws4CBgLfFdSH0l9gO8AJwEjgbNzx/lqOtaBwDrg/Bp+HzMzq1CzIhIRqyPi4TS/CXgMGNzNLuOA6RGxOSKeADqAo9LUERHLIuKvwHRgnCQB7wJuS/tPA06ryZcxM7Oq6tImIqkNOAx4MIUukvSopCmSBqTYYGBFbreVKdZV/HXA+ojYUhGvdv4JkuZJmvfMM8/0xFcyMzPqUEQkvRb4CfCpiNgIXA+8ARgFrAa+UescImJyRLRHRPvAgQNrfTozs16jby0PLmkXsgJyc0TcDhART+fW3wj8LC2uAobmdh+SYnQRfxboL6lvuhrJb29mZnVQsyKS2ixuAh6LiGty8UERsTotng4sSvMzgB9JugbYDxgBPAQIGCFpOFmROAt4f0SEpDnAGWTtJOOBO2v1fcxeydom3tXluuWTTqljJtZqankl8nbgQ8BCSQtS7LNkvatGAQEsBz4KEBGLJd0KLCHr2XVhRGwFkHQRMAvoA0yJiMXpeJ8Bpkv6MvAIWdEyM7M6qVkRiYj7ya4iKs3sZp+rgaurxGdW2y8ilpH13jIzswbwE+tmZlaai4iZmZXmImJmZqW5iJiZWWkuImZmVpqLiJmZleYiYmZmpbmImJlZaS4iZmZWmouImZmV5iJiZmaluYiYmVlpLiJmZlaai4iZmZXmImJmZqW5iJiZWWkuImZmVpqLiJmZleYiYmZmpbmImJlZadstIpLeK6lfmv+8pNslHV771MzMrNkVuRL5PxGxSdIxwLuBm4Dra5uWmZm1giJFZGv6PAWYHBF3AbvWLiUzM2sVRYrIKkk3AO8DZkrareB+Zmb2ClekGJwJzAJOjIj1wN7AZbVMyszMWsN2i0hEvACsAY5JoS3A0lomZWZmraFI76wrgM8Al6fQLsAPa5mUmZm1hiK3s04H3gM8DxARfwL6bW8nSUMlzZG0RNJiSZek+N6SZktamj4HpLgkXSepQ9Kj+W7Eksan7ZdKGp+LHyFpYdrnOknasa9vZmY7o0gR+WtEBBAAkvYoeOwtwKURMRIYDVwoaSQwEbgnIkYA96RlgJOAEWmaQOpGLGlv4ArgaOAo4IrOwpO2uSC339iCuZmZWQ8oUkRuTb2z+ku6APh/wI3b2ykiVkfEw2l+E/AYMBgYB0xLm00DTkvz44DvR+aBdL5BwInA7IhYGxHrgNnA2LRuz4h4IBW57+eOZWZmddB3extExNclnQBsBN4EfCEiZu/ISSS1AYcBDwL7RsTqtOopYN80PxhYkdttZYp1F19ZJV7t/BPIrm4YNmzYjqRuZmbd2G4RAUhFY4cKRydJrwV+AnwqIjbmmy0iIiRFmePuiIiYDEwGaG9vr/n5zMx6iy5vZ0naJGljlWmTpI1FDi5pF7ICcnNE3J7CT6dbUaTPNSm+Chia231IinUXH1IlbmZmddJlEYmIfhGxZ5WpX0Tsub0Dp55SNwGPRcQ1uVUzgM4eVuOBO3Pxc1IvrdHAhnTbaxYwRtKA1KA+BpiV1m2UNDqd65zcsczMrA4K3c5K3W2PIeuhdX9EPFJgt7cDHwIWSlqQYp8FJpE11p8PPEn2RDzATOBkoAN4ATgPICLWSvoSMDdtd1VErE3znwCmArsDP0+TmZnVyXaLiKQvAO8FOm9HTZX0rxHx5e72i4j7ga6e2zi+yvYBXNjFsaYAU6rE5wEHd5eHmZnVTpErkQ8Ah0bEXwAkTQIWAN0WETMze+Ur8pzIn4BX55Z3ww3YZmZGsSuRDcBiSbPJ2kROAB6SdB1ARFxcw/zMzKyJFSkid6Sp0721ScXMzFpNkSfWp21vGzMz652KDAV/qqRHJK3d0YcNzczsla3I7axvAn8HLEzdcM2sC20T7+py3fJJp9QxE7P6KNI7awWwyAXEzMwqFbkS+QdgpqRfAZs7gxVDmZiZWS9UpIhcDTxH9qzIrrVNx8zMWkmRIrJfRHhoETMz20aRNpGZksbUPBMzM2s5RYrIx4FfSPoPd/E1M7O8Ig8b9qtHImZm1nqKvk9kADCC3ECMEXFfrZIyM7PWUOR9Ih8BLiF7/ewCYDTwW+BdNc3MzMyaXpE2kUuAI4EnI+I44DBgfS2TMjOz1lCkiPwl90Kq3SLi98CbapuWmZm1giJtIisl9Qd+CsyWtI7s3ehmZtbLFemddXqavVLSHGAv4Bc1zcrMzFpCkaHg3yBpt85FoA14TS2TMjOz1lCkTeQnwFZJBwKTgaHAj2qalZmZtYQiReSliNgCnA58KyIuAwbVNi0zM2sFRYrIi5LOBsYDP0uxXWqXkpmZtYoiReQ84G3A1RHxhKThwA9qm5aZmbWCIr2zlgAX55afAL5ay6TMzKw1FLkSMTMzq6pmRUTSFElrJC3Kxa6UtErSgjSdnFt3uaQOSY9LOjEXH5tiHZIm5uLDJT2Y4j+W5LcumpnVWZdFRNIP0uclJY89FRhbJX5tRIxK08x0jpHAWcBBaZ/vSuojqQ/wHeAkYCRwdtoWsltq10bEgcA64PySeZqZWUndXYkcIWk/4MOSBkjaOz9t78BpqPi1BfMYB0yPiM2pzaUDOCpNHRGxLCL+CkwHxkkS2SjCt6X9pwGnFTyXmZn1kO4a1r8H3AMcAMwne1q9U6R4GRdJOgeYB1waEeuAwcADuW1WphjAior40cDrgPXp+ZXK7bchaQIwAWDYsGEl0zYzs0pdXolExHUR8RZgSkQcEBHDc1PZAnI98AZgFLAa+EbJ4+yQiJgcEe0R0T5w4MB6nNLMrFco0sX345IOBd6RQvdFxKNlThYRT3fOS7qRlx9eXEU2nEqnISlGF/Fngf6S+qarkfz2ZmZWJ0UGYLwYuBl4fZpulvTJMieTlB8u5XSgs+fWDOAsSbulhxlHAA8Bc4ERqSfWrmSN7zMiIoA5wBlp//HAnWVyMjOz8oq8T+QjwNER8TyApK+SvR73W93tJOkW4FhgH0krgSuAYyWNImtTWQ58FCAiFku6FVgCbAEujIit6TgXAbOAPmS31hanU3wGmC7py8AjwE3FvrKZmfWUIkVEwNbc8lb+tpG9qog4u0q4y//oI+Jq4Ooq8ZnAzCrxZWS9t8zMrEGKFJF/AR6UdEdaPg3/1m9mZhRrWL9G0r3AMSl0XkQ8UtOszMysJRS5EiEiHgYernEuZmbWYjwAo5mZleYiYmZmpXVbRNIgiHPqlYyZmbWWbotIelbjJUl71SkfMzNrIUUa1p8DFkqaDTzfGYyIi7vexczMeoMiReT2NJmZmf2NIs+JTJO0OzAsIh6vQ05mZtYiigzA+D+BBcAv0vIoSTNqnJeZmbWAIrezriQbo+pegIhYIKns+0TM7BWmbeJdXa5bPumUOmZijVDkOZEXI2JDReylWiRjZmatpciVyGJJ7wf6SBoBXAz8prZpmZlZKyhyJfJJ4CBgM3ALsBH4VA1zMjOzFlGkd9YLwOfSy6giIjbVPi0zM2sFRXpnHSlpIfAo2UOHv5N0RO1TMzOzZlekTeQm4BMR8WsASceQvajqkFomZmZmza9Im8jWzgICEBH3k70H3czMerkur0QkHZ5mfyXpBrJG9QDeR3pmxMzMerfubmd9o2L5itx81CAXMzNrMV0WkYg4rp6JmJlZ69luw7qk/sA5QFt+ew8Fb2ZmRXpnzQQeABbi4U7MzCynSBF5dUT875pnYmZmLadIF98fSLpA0iBJe3dONc/MzMyaXpErkb8CXwM+x8u9sgLwcPBmZr1ckSuRS4EDI6ItIoanabsFRNIUSWskLcrF9pY0W9LS9DkgxSXpOkkdkh7NPaOCpPFp+6WSxufiR0hamPa5TpJ27KubmdnOKlJEOoAXShx7KjC2IjYRuCciRgD3pGWAk4ARaZoAXA9Z0SF7PuVoshdjXdFZeNI2F+T2qzyXmZnVWJHbWc8DCyTNIRsOHth+F9+IuE9SW0V4HHBsmp9G9uT7Z1L8+xERwAOS+ksalLadHRFrASTNBsZKuhfYMyIeSPHvA6cBPy/wfczMrIcUKSI/TVNP2DciVqf5p4B90/xgYEVuu5Up1l18ZZV4VZImkF3hMGzYsJ1I38zM8oq8T2RaLU4cESGpLsOnRMRkYDJAe3u7h2wxM+shRZ5Yf4IqY2UVaVyv4mlJgyJidbpdtSbFVwFDc9sNSbFVvHz7qzN+b4oPqbK9mZnVUZGG9XbgyDS9A7gO+GHJ880AOntYjQfuzMXPSb20RgMb0m2vWcAYSQNSg/oYYFZat1HS6NQr65zcsczMrE6K3M56tiL0TUnzgS90t5+kW8iuIvaRtJKsl9Uk4FZJ5wNPAmemzWcCJ/NyT7Dz0rnXSvoSMDdtd1VnIzvwCbIeYLuTNai7Ud3MrM6K3M46PLf4KrIrkyLF5+wuVh1fZdsALuziOFOAKVXi84CDt5eHmZnVTpHeWfn3imwBlvPyFYSZmfViRa4o/F4RMzOrqsjtrN2A/8W27xO5qnZpmZlZKyhyO+tOYAMwn9wT62ZmZkWKyJCI8LhUZma2jSLPifxG0ltrnomZmbWcIlcixwDnpifXNwMi65V7SE0zMzOzplekiJxU8yzMzKwlFeni+2Q9EjEzs9ZTpE3EzMysKhcRMzMrzUXEzMxKcxExM7PSXETMzKw0FxEzMyvNRcTMzEpzETEzs9JcRMzMrLQiw56Y9SptE+/qct3ySafUMROz5ucrETMzK81FxMzMSnMRMTOz0lxEzMysNBcRMzMrzUXEzMxKcxExM7PSXETMzKy0hhQRScslLZS0QNK8FNtb0mxJS9PngBSXpOskdUh6VNLhueOMT9svlTS+Ed/FzKw3a+SVyHERMSoi2tPyROCeiBgB3JOWAU4CRqRpAnA9ZEUHuAI4GjgKuKKz8JiZWX000+2sccC0ND8NOC0X/35kHgD6SxoEnAjMjoi1EbEOmA2MrXPOZma9WqOKSAB3S5ovaUKK7RsRq9P8U8C+aX4wsCK378oU6ypuZmZ10qgBGI+JiFWSXg/MlvT7/MqICEnRUydLhWoCwLBhw3rqsGZmvV5DrkQiYlX6XAPcQdam8XS6TUX6XJM2XwUMze0+JMW6ilc73+SIaI+I9oEDB/bkVzEz69XqXkQk7SGpX+c8MAZYBMwAOntYjQfuTPMzgHNSL63RwIZ022sWMEbSgNSgPibFzMysThpxO2tf4A5Jnef/UUT8QtJc4FZJ5wNPAmem7WcCJwMdwAvAeQARsVbSl4C5aburImJt/b6GmZnVvYhExDLg0CrxZ4Hjq8QDuLCLY00BpvR0jmZmVozfbGhmTctvmWx+zfSciJmZtRgXETMzK81FxMzMSnMRMTOz0lxEzMysNBcRMzMrzUXEzMxKcxExM7PSXETMzKw0FxEzMyvNRcTMzEpzETEzs9JcRMzMrDQXETMzK81FxMzMSnMRMTOz0lxEzMysNBcRMzMrza/HtZbk16aaNQdfiZiZWWkuImZmVpqLiJmZleYiYmZmpblh3cx6ne46ZoA7Z+wIX4mYmVlpLiJmZlaai4iZmZXW8kVE0lhJj0vqkDSx0fmYmfUmLd2wLqkP8B3gBGAlMFfSjIhY0tjMDNx4adYbtHQRAY4COiJiGYCk6cA4wEXEzGrGw+68TBHR6BxKk3QGMDYiPpKWPwQcHREXVWw3AZiQFt8EPF7XRLu2D/DnRiexHc2eY7PnB86xJzR7ftD8Oe5sfvtHxMDKYKtfiRQSEZOByY3Oo5KkeRHR3ug8utPsOTZ7fuAce0Kz5wfNn2Ot8mv1hvVVwNDc8pAUMzOzOmj1IjIXGCFpuKRdgbOAGQ3Oycys12jp21kRsUXSRcAsoA8wJSIWNzitHdF0t9iqaPYcmz0/cI49odnzg+bPsSb5tXTDupmZNVar384yM7MGchExM7PSXEQaQNJQSXMkLZG0WNIljc6pGkl9JD0i6WeNzqUaSf0l3Sbp95Iek/S2RueUJ+nv09/vIkm3SHp1E+Q0RdIaSYtysb0lzZa0NH0OaMIcv5b+nh+VdIek/g1MsWqOuXWXSgpJ+zQit5RD1fwkfTL9OS6W9H974lwuIo2xBbg0IkYCo4ELJY1scE7VXAI81ugkuvFPwC8i4s3AoTRRrpIGAxcD7RFxMFnHj7MamxUAU4GxFbGJwD0RMQK4Jy030lS2zXE2cHBEHAL8f+DyeidVYSrb5oikocAY4I/1TqjCVCryk3Qc2Ygeh0bEQcDXe+JELiINEBGrI+LhNL+J7D+/wY3N6m9JGgKcAvxzo3OpRtJewDuBmwAi4q8Rsb6hSW2rL7C7pL7Aa4A/NTgfIuI+YG1FeBwwLc1PA06rZ06VquUYEXdHxJa0+ADZM2EN08WfI8C1wD8ADe2x1EV+HwcmRcTmtM2anjiXi0iDSWoDDgMebHAqlb5J9sPwUoPz6Mpw4BngX9Itt3+WtEejk+oUEavIftP7I7Aa2BARdzc2qy7tGxGr0/xTwL6NTKaADwM/b3QSlSSNA1ZFxO8anUsX3gi8Q9KDkn4l6cieOKiLSANJei3wE+BTEbGx0fl0knQqsCYi5jc6l270BQ4Hro+Iw4DnafxtmP+S2hXGkRW7/YA9JH2wsVltX2R9/pu237+kz5HdDr650bnkSXoN8FngC43OpRt9gb3JbqFfBtwqSTt7UBeRBpG0C1kBuTkibm90PhXeDrxH0nJgOvAuST9sbErbWAmsjIjOK7jbyIpKs3g38EREPBMRLwK3A/+9wTl15WlJgwDSZ4/c5uhpks4FTgU+EM33gNsbyH5h+F36uRkCPCzpvzU0q7+1Erg9Mg+R3WXY6cZ/F5EGSNX/JuCxiLim0flUiojLI2JIRLSRNQb/MiKa6rfoiHgKWCHpTSl0PM31CoA/AqMlvSb9fR9PEzX8V5gBjE/z44E7G5hLVZLGkt1efU9EvNDofCpFxMKIeH1EtKWfm5XA4enfabP4KXAcgKQ3ArvSA6MOu4g0xtuBD5H9hr8gTSc3OqkW9EngZkmPAqOAf2xsOi9LV0i3AQ8DC8l+1ho+LIakW4DfAm+StFLS+cAk4ARJS8muoCY1YY7fBvoBs9PPy/eaMMem0UV+U4ADUrff6cD4nrii87AnZmZWmq9EzMysNBcRMzMrzUXEzMxKcxExM7PSXETMzKw0FxF7xZL0XA2OOSrfHVvSlZI+vRPHe28agXhOz2RYOo/ljRx11lqXi4jZjhkF9OQzPecDF0TEcT14TLO6cRGxXkHSZZLmpvdRfDHF2tJVwI3p/Qp3S9o9rTsybbsgvctikaRdgauA96X4+9LhR0q6V9IySRd3cf6zJS1Mx/lqin0BOAa4SdLXKrYfJOm+dJ5Fkt6R4tdLmpfy/WJu++WSvpK2nyfpcEmzJP1B0sfSNsemY94l6XFJ35O0zf8Bkj4o6aF0rBuUvVemj6SpKZeFkv5+J/9K7JUiIjx5ekVOwHPpcwzZ0+Ii+8XpZ2TDyLeRDeY3Km13K/DBNL8IeFuanwQsSvPnAt/OneNK4DfAbmTjED0L7FKRx35kw6AMJBsE75fAaWndvWTvHKnM/VLgc2m+D9Avze+di90LHJKWlwMfT/PXAo+SPeE9EHg6xY8F/gIckPafDZyR238f4C3Av3V+B+C7wDnAEcDsXH79G/3366k5Jl+JWG8wJk2PkA1D8mZgRFr3REQsSPPzgTZlb83rFxG/TfEfbef4d0XE5oj4M9nghZVDqR8J3BvZYIydI9C+czvHnAucJ+lK4K2RvXcG4ExJD6fvchCQf5nZjPS5EHgwIjZFxDPAZr38JsCHImJZRGwFbiG7Eso7nqxgzJW0IC0fACwjGzLjW2kcq6YZddoaq2+jEzCrAwFfiYgb/iaYvctlcy60Fdi9xPErj7HTP1cRcZ+kd5K9GGyqpGuAXwOfBo6MiHWSpgL5V+525vFSRU4v5XKqHOeoclnAtIjY5s2Bkg4FTgQ+BpxJ9l4P6+V8JWK9wSzgw+n9LUgaLOn1XW0c2RsSN0k6OoXyr7XdRHabaEc8BPwPSftI6gOcDfyqux0k7U92G+pGsrdLHg7sSfbelA2S9gVO2sE8AI6SNDy1hbwPuL9i/T3AGZ1/Psrev75/6rn1qoj4CfB5mmvYfWsgX4nYK15E3C3pLcBvs1HZeQ74INlVQ1fOB26U9BLZf/gbUnwOMDHd6vlKwfOvljQx7Suy21/bG279WOAySS+mfM+JiCckPQL8HlgB/HuR81eYSzYi7oEpnzsqcl0i6fPA3anQvAhcCPwH2VskO3/xbPQ7zq1JeBRfsyokvTYinkvzE4FBEXFJg9PaKZKOBT4dEac2OBV7BfGViFl1p0i6nOxn5EmyXllmVsFXImZmVpob1s3MrDQXETMzK81FxMzMSnMRMTOz0lxEzMystP8EjGM+0BHzMG8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Text와 Summary의 최소, 최대, 평균 길이를 구하고 또한 길이 분포를 시각화\n",
    "# 길이 분포 출력\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "summary_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('제목의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('제목의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('제목의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('headlines')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('text')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('headlines')\n",
    "plt.hist(summary_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "appreciated-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 45\n",
    "headlines_max_len = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "provincial-enzyme",
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "refined-farmer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 45 이하인 샘플의 비율: 0.9941744611630744\n",
      "전체 샘플 중 길이가 12 이하인 샘플의 비율: 0.9880337535583571\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(headlines_max_len,  data['headlines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "shaped-local",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97787\n",
      "96620\n"
     ]
    }
   ],
   "source": [
    "## 샘플들의 길이 중에서 max length 이하인 데이터들의 갯수를 알아보기\n",
    "data = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "print(len(data))\n",
    "data = data[data['headlines'].apply(lambda x: len(x.split()) <= headlines_max_len)]\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-signature",
   "metadata": {},
   "source": [
    "시작토큰과 종료토큰 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "completed-rugby",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "      <td>saurav kant alumnus upgrad iiit pg program mac...</td>\n",
       "      <td>sostoken upgrad learner switches to career in ...</td>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "      <td>new zealand defeated india wickets fourth odi ...</td>\n",
       "      <td>sostoken new zealand end rohit sharma led indi...</td>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "      <td>aegon life iterm insurance plan customers enjo...</td>\n",
       "      <td>sostoken aegon life iterm insurance plan helps...</td>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rahat fateh ali khan denies getting notice for...</td>\n",
       "      <td>pakistani singer rahat fateh ali khan denied r...</td>\n",
       "      <td>sostoken rahat fateh ali khan denies getting n...</td>\n",
       "      <td>rahat fateh ali khan denies getting notice for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>india get all out for their lowest odi total i...</td>\n",
       "      <td>india recorded lowest odi total new zealand af...</td>\n",
       "      <td>sostoken india get all out for their lowest od...</td>\n",
       "      <td>india get all out for their lowest odi total i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upgrad learner switches to career in ml al wit...   \n",
       "2  new zealand end rohit sharma led india match w...   \n",
       "3  aegon life iterm insurance plan helps customer...   \n",
       "5  rahat fateh ali khan denies getting notice for...   \n",
       "6  india get all out for their lowest odi total i...   \n",
       "\n",
       "                                                text  \\\n",
       "0  saurav kant alumnus upgrad iiit pg program mac...   \n",
       "2  new zealand defeated india wickets fourth odi ...   \n",
       "3  aegon life iterm insurance plan customers enjo...   \n",
       "5  pakistani singer rahat fateh ali khan denied r...   \n",
       "6  india recorded lowest odi total new zealand af...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0  sostoken upgrad learner switches to career in ...   \n",
       "2  sostoken new zealand end rohit sharma led indi...   \n",
       "3  sostoken aegon life iterm insurance plan helps...   \n",
       "5  sostoken rahat fateh ali khan denies getting n...   \n",
       "6  sostoken india get all out for their lowest od...   \n",
       "\n",
       "                                      decoder_target  \n",
       "0  upgrad learner switches to career in ml al wit...  \n",
       "2  new zealand end rohit sharma led india match w...  \n",
       "3  aegon life iterm insurance plan helps customer...  \n",
       "5  rahat fateh ali khan denies getting notice for...  \n",
       "6  india get all out for their lowest odi total i...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decoder - 시작토큰 입력받아 문장 생성하기 시작하고, 종료 토큰을 예측한 순간 문장생성 stop\n",
    "# headlines데이터에 시작토큰과 종료토큰을 추가\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x: 'sostoken ' + x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x: x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "stopped-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['text'])            # 인코더 입력\n",
    "decoder_input = np.array(data['decoder_input'])   # 디코더 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더 레이블"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-religion",
   "metadata": {},
   "source": [
    "train, test data 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "occasional-poverty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47959  6702 47404 ... 24612 35809 58219]\n"
     ]
    }
   ],
   "source": [
    "# encoder_input과 크기와 형태가 같은 순서가 섞인 정수 시퀀스 만듬\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "congressional-belly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 정수시퀀스를 이용해서 다시 데이터의 샘플 순서를 정의해줌\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "external-wilson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of test data : 19324\n"
     ]
    }
   ],
   "source": [
    "# train, test 8:2 비율로 분리\n",
    "n_of_val = int(len(encoder_input) * 0.2)\n",
    "print('number of test data :', n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "decreased-surveillance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 77296\n",
      "훈련 레이블의 개수 : 77296\n",
      "테스트 데이터의 개수 : 19324\n",
      "테스트 레이블의 개수 : 19324\n"
     ]
    }
   ],
   "source": [
    "## train과 test를 split\n",
    "encoder_input_train = encoder_input[ : -n_of_val]\n",
    "decoder_input_train = decoder_input[ : -n_of_val]\n",
    "decoder_target_train = decoder_target[ :-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val : ]\n",
    "decoder_input_test = decoder_input[-n_of_val : ]\n",
    "decoder_target_test = decoder_target[-n_of_val : ]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-insert",
   "metadata": {},
   "source": [
    "### 정수 인코딩\n",
    "\n",
    "Keras의 토크나이저를 사용하여, 입력된 훈련 데이터로부터 단어 집합을 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "multiple-soldier",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-setting",
   "metadata": {},
   "source": [
    "등장 빈도수가 7회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "direct-prevention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 69076\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 47110\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 21966\n",
      "단어 집합에서 희귀 단어의 비율: 68.20024321037698\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.4350299445274888\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "monetary-relationship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21966\n"
     ]
    }
   ],
   "source": [
    "src_vocab = total_cnt - rare_cnt\n",
    "print(src_vocab)\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab)  # 가장 빈도가 높은 src_vocap개의 단어만 선택하도록 tokenizer 객체 생성\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 인덱스 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-heavy",
   "metadata": {},
   "source": [
    "texts_to_sequences()을 통하여 정수 인코딩 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "suspected-silver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[581, 14, 1361, 1772, 1710, 1572, 211, 83, 12446, 1630, 1047, 9392, 1710, 155, 211, 83, 246, 2957, 154, 13675, 1813, 5271, 1772, 1710, 502, 1300, 200, 2805, 9940, 120, 155, 384, 336], [32, 7, 10, 2148, 4204, 3131, 1977, 555, 8467, 95, 1655, 1795, 941, 289, 5333, 941, 1383, 493, 2070, 5333, 941, 4455, 1562, 6280, 1048, 514, 15, 51, 245, 1383, 493, 2070, 8622, 8467, 514, 128, 560, 941, 80, 1094, 13250, 351], [29, 1635, 183, 3270, 17, 7273, 5334, 10600, 4018, 176, 9, 3062, 7922, 11161, 371, 7273, 8901, 170, 3403, 4018, 244, 1231, 20471, 8, 1468, 87, 7273, 397, 227, 127]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train)\n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "engaging-manual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 29929\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수 : 19623\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 10306\n",
      "단어 집합에서 희귀 단어의 비율 : 65.56517090447393\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율 : 4.7635635726600585\n"
     ]
    }
   ],
   "source": [
    "# headlines도 동일한 작업 수행\n",
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "\n",
    "\n",
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index)  #단어수\n",
    "\n",
    "rare_cnt = 0    # 등장빈도수가 threshold보다 작은 단어 개수 카운트\n",
    "total_freq = 0  # 훈련데이터의 전체 단어 빈도수 총합\n",
    "rare_freq = 0   # 등장빈도수가 threshold보다 작은 단어의 등장 빈도수의 총합\n",
    "\n",
    "for key,value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "    if value < threshold:\n",
    "        rare_cnt += 1\n",
    "        rare_freq += value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print(f'등장 빈도가 {threshold - 1}번 이하인 희귀 단어의 수 : {rare_cnt}')\n",
    "print(f'단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 {total_cnt - rare_cnt}')\n",
    "print('단어 집합에서 희귀 단어의 비율 :', (rare_cnt / total_cnt)*100)\n",
    "print('전체 등장 빈도에서 희귀 단어 등장 빈도 비율 :', (rare_freq/total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "reverse-watch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input  [[1, 1625, 3, 997, 6745, 183, 254, 7, 1031, 1484], [1, 2870, 2537, 4354, 5, 3289, 729, 1738, 255, 3215], [1, 35, 511, 6, 3748, 9439, 3290, 4104, 53], [1, 45, 2637, 17, 23, 4, 4105, 1228, 1606, 366, 119], [1, 123, 1694, 606, 46, 149, 248, 3, 6746, 565, 383]]\n",
      "decoder  [[1625, 3, 997, 6745, 183, 254, 7, 1031, 1484, 2], [2870, 2537, 4354, 5, 3289, 729, 1738, 255, 3215, 2], [35, 511, 6, 3748, 9439, 3290, 4104, 53, 2], [45, 2637, 17, 23, 4, 4105, 1228, 1606, 366, 119, 2], [123, 1694, 606, 46, 149, 248, 3, 6746, 565, 383, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = total_cnt - rare_cnt\n",
    "tar_tokenizer = Tokenizer(num_words = tar_vocab)\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-seven",
   "metadata": {},
   "source": [
    "훈련 데이터와 테스트 데이터에 대해서 요약문의 길이가 1인 경우의 인덱스를 각각 drop_train과 drop_test에 라는 변수에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "visible-evaluation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 1\n",
      "삭제할 테스트 데이터의 개수 : 0\n",
      "훈련 데이터의 개수 : 77295\n",
      "훈련 레이블의 개수 : 77295\n",
      "테스트 데이터의 개수 : 19324\n",
      "테스트 레이블의 개수 : 19324\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :',len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :',len(drop_test))\n",
    "\n",
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-rolling",
   "metadata": {},
   "source": [
    "### 패딩하기\n",
    "\n",
    "학습할 때 동일한 길이여야지 모델 학습 시 무리없이 진행하기 위해서(서로 다른 길이의 샘플들을 병렬처리하기 위해) 같은 길이로 맞춰줌."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "excessive-outside",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=headlines_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-secretariat",
   "metadata": {},
   "source": [
    "## 어텐션 메커니즘 사용하기 (추상적 요약)\n",
    "\n",
    "일반적인 seq2seq보다는 어텐션 메커니즘 을 사용한 seq2seq를 사용하는 것이 더 나은 성능을 얻을 수 있다\n",
    "\n",
    "- 원문을 첫번째 RNN인 인코더로 입력한다.\n",
    "- 인코더는 입력받은 원문을 하나의 고정된 벡터로 변환한다. 이 벡터를 컨텍스트 벡터(문맥정보를 가지고 있는 벡터)라고 한다.\n",
    "- 두번째 RNN인 디코더는 이 컨텍스트 벡터를 전달받아 한단어씩 생성내서 요약문장을 완성한다.\n",
    "\n",
    "\n",
    "### 모델설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "temporal-grass",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "stainless-norwegian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences = True, return_state = True, dropout = 0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = [state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "neutral-insurance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 45)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 45, 128)      2811648     input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 45, 256), (N 394240      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, 45, 256), (N 525312      lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 128)    1319168     input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, 45, 256), (N 525312      lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   [(None, None, 256),  394240      embedding_3[0][0]                \n",
      "                                                                 lstm_6[0][1]                     \n",
      "                                                                 lstm_6[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 10306)  2648642     lstm_7[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 8,618,562\n",
      "Trainable params: 8,618,562\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation = 'softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-keyboard",
   "metadata": {},
   "source": [
    "어텐션 매커니즘 함수 다운"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "handed-listening",
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-outline",
   "metadata": {},
   "source": [
    "설계한 디코더의 출력층을 수정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "formal-milan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 45)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 45, 128)      2811648     input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 45, 256), (N 394240      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, 45, 256), (N 525312      lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 128)    1319168     input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, 45, 256), (N 525312      lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   [(None, None, 256),  394240      embedding_3[0][0]                \n",
      "                                                                 lstm_6[0][1]                     \n",
      "                                                                 lstm_6[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_6[0][0]                     \n",
      "                                                                 lstm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_7[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, None, 10306)  5286978     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 11,388,226\n",
      "Trainable params: 11,388,226\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis = -1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-reality",
   "metadata": {},
   "source": [
    "### 모델 훈련하기\n",
    "\n",
    "설계한 모델을 가지고 훈련을 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "intensive-sword",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "302/302 [==============================] - 222s 698ms/step - loss: 6.0247 - val_loss: 5.1965\n",
      "Epoch 2/50\n",
      "302/302 [==============================] - 211s 700ms/step - loss: 5.1262 - val_loss: 4.8239\n",
      "Epoch 3/50\n",
      "302/302 [==============================] - 212s 701ms/step - loss: 4.7570 - val_loss: 4.5609\n",
      "Epoch 4/50\n",
      "302/302 [==============================] - 213s 705ms/step - loss: 4.4591 - val_loss: 4.3675\n",
      "Epoch 5/50\n",
      "302/302 [==============================] - 212s 701ms/step - loss: 4.2452 - val_loss: 4.2154\n",
      "Epoch 6/50\n",
      "302/302 [==============================] - 213s 704ms/step - loss: 4.0557 - val_loss: 4.1060\n",
      "Epoch 7/50\n",
      "302/302 [==============================] - 211s 699ms/step - loss: 3.9060 - val_loss: 4.0081\n",
      "Epoch 8/50\n",
      "302/302 [==============================] - 212s 703ms/step - loss: 3.7711 - val_loss: 3.9305\n",
      "Epoch 9/50\n",
      "302/302 [==============================] - 212s 701ms/step - loss: 3.6575 - val_loss: 3.8772\n",
      "Epoch 10/50\n",
      "302/302 [==============================] - 213s 705ms/step - loss: 3.5532 - val_loss: 3.8272\n",
      "Epoch 11/50\n",
      "302/302 [==============================] - 213s 705ms/step - loss: 3.4508 - val_loss: 3.7724\n",
      "Epoch 12/50\n",
      "302/302 [==============================] - 214s 708ms/step - loss: 3.3733 - val_loss: 3.7360\n",
      "Epoch 13/50\n",
      "302/302 [==============================] - 212s 702ms/step - loss: 3.2973 - val_loss: 3.7132\n",
      "Epoch 14/50\n",
      "302/302 [==============================] - 212s 703ms/step - loss: 3.2257 - val_loss: 3.6883\n",
      "Epoch 15/50\n",
      "302/302 [==============================] - 211s 698ms/step - loss: 3.1638 - val_loss: 3.6567\n",
      "Epoch 16/50\n",
      "302/302 [==============================] - 211s 700ms/step - loss: 3.1053 - val_loss: 3.6425\n",
      "Epoch 17/50\n",
      "302/302 [==============================] - 212s 702ms/step - loss: 3.0525 - val_loss: 3.6214\n",
      "Epoch 18/50\n",
      "302/302 [==============================] - 212s 702ms/step - loss: 3.0098 - val_loss: 3.6108\n",
      "Epoch 19/50\n",
      "302/302 [==============================] - 212s 701ms/step - loss: 2.9541 - val_loss: 3.6052\n",
      "Epoch 20/50\n",
      "302/302 [==============================] - 211s 700ms/step - loss: 2.9104 - val_loss: 3.5877\n",
      "Epoch 21/50\n",
      "302/302 [==============================] - 212s 700ms/step - loss: 2.8663 - val_loss: 3.5832\n",
      "Epoch 22/50\n",
      "302/302 [==============================] - 212s 701ms/step - loss: 2.8291 - val_loss: 3.5698\n",
      "Epoch 23/50\n",
      "302/302 [==============================] - 212s 703ms/step - loss: 2.7979 - val_loss: 3.5687\n",
      "Epoch 24/50\n",
      "302/302 [==============================] - 213s 705ms/step - loss: 2.7621 - val_loss: 3.5693\n",
      "Epoch 25/50\n",
      "302/302 [==============================] - 211s 699ms/step - loss: 2.7295 - val_loss: 3.5581\n",
      "Epoch 26/50\n",
      "302/302 [==============================] - 212s 701ms/step - loss: 2.6900 - val_loss: 3.5499\n",
      "Epoch 27/50\n",
      "302/302 [==============================] - 213s 705ms/step - loss: 2.6551 - val_loss: 3.5517\n",
      "Epoch 28/50\n",
      "302/302 [==============================] - 213s 705ms/step - loss: 2.6297 - val_loss: 3.5478\n",
      "Epoch 29/50\n",
      "302/302 [==============================] - 212s 701ms/step - loss: 2.6091 - val_loss: 3.5523\n",
      "Epoch 30/50\n",
      "302/302 [==============================] - 213s 705ms/step - loss: 2.5795 - val_loss: 3.5500\n",
      "Epoch 00030: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 2)\n",
    "history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size = 256, callbacks=[es], epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-anxiety",
   "metadata": {},
   "source": [
    "훈련 데이터의 손실과 검증 데이터의 손실이 줄어드는 과정을 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "returning-gathering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-table",
   "metadata": {},
   "source": [
    "### 인퍼런스 모델 구현하기\n",
    "\n",
    "테스트 단계에서는 정수 인덱스 행렬로 존재하던 텍스트 데이터를 실제 데이터로 복원해야 하므로, 필요한 3개의 사전을 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "overall-canyon",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-keyboard",
   "metadata": {},
   "source": [
    "인코더 모델과 디코더 모델을 분리해서 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "deluxe-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-angle",
   "metadata": {},
   "source": [
    "어텐션 메커니즘을 사용하는 출력층을 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "alike-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-peninsula",
   "metadata": {},
   "source": [
    "인퍼런스 단계에서 단어 시퀀스를 완성하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "demographic-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (headlines_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-grocery",
   "metadata": {},
   "source": [
    "### 모델 테스트하기\n",
    "\n",
    "정수 시퀀스를 텍스트 시퀀스로 변환하는 함수와 주어진 정수 시퀀스를 텍스트 시퀀스로 변환하는 함수를 만들어본다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "excited-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-climate",
   "metadata": {},
   "source": [
    "## 실제 결과와 요약문 비교하기 (추상적 요약)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "partial-tomorrow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : supreme court collegium cleared names appointment judges high courts collegium reportedly recommended names bombay high court nine punjab haryana high court six high courts telangana andhra pradesh patna four three names cleared delhi jammu kashmir respectively \n",
      "실제 요약 : sc clears over names of hc judges \n",
      "예측 요약 :  sc to hear judges plea against judges who judges sc\n",
      "\n",
      "\n",
      "원문 : two terrorists allegedly barged house pdp worker jammu kashmir bandipora sunday abduct slit wife throat while trying rescue woman later succumbed injuries hospital srinagar meanwhile terrorists managed escape after attacking woman \n",
      "실제 요약 : terrorists try to abduct pdp man in slit wife throat \n",
      "예측 요약 :  terrorists killed in encounter in jammu and kashmir\n",
      "\n",
      "\n",
      "원문 : after bengaluru police rescued abandoned newborn stuffed plastic bag policewoman taking care weak baby breastfed could not bear felt like child crying feed baby policewoman said baby named kumaraswamy after karnataka new cm hd kumaraswamy \n",
      "실제 요약 : bengaluru policewoman abandoned newborn \n",
      "예측 요약 :  luru cops rescue baby from baby after baby survivor\n",
      "\n",
      "\n",
      "원문 : aam aadmi party wednesday launched metro satyagraha protest delhi metro fare hike demand immediate party supporters staged demonstrations outside various metro stations shouted slogans metro authorities bjp centre notably fares increased maximum tuesday despite opposition delhi government \n",
      "실제 요약 : aap launches satyagraha against delhi metro fare hike \n",
      "예측 요약 :  aap metro to be part of metro stations in delhi\n",
      "\n",
      "\n",
      "원문 : rss leader indresh kumar said western tradition valentine day responsible rape illegitimate children violence women love pure but western culture changed passion somehow business responsible increasing cases triple talaq domestic violence female etc kumar added \n",
      "실제 요약 : rss leader blames valentine day for rape kids \n",
      "예측 요약 :  rss rss wing compares father of kids to clean kids\n",
      "\n",
      "\n",
      "원문 : italian court told couple pick name month old daughter named not able change court observed word cannot attributed female sex violated presidential order states children names must sex \n",
      "실제 요약 : change name or we will court to parents who named kid \n",
      "예측 요약 :  parents to be woman who is gay woman\n",
      "\n",
      "\n",
      "원문 : rejecting offer last month us president donald trump talks without iran supreme leader ayatollah ali khamenei banned holding direct talks us america never remains loyal promises talks gives empty words never goals talks khamenei said \n",
      "실제 요약 : iran supreme leader bans holding direct talks with us \n",
      "예측 요약 :  trump threatens to us supreme leader talks with iran\n",
      "\n",
      "\n",
      "원문 : turkish embassy denmark copenhagen attacked petrol bombs unknown assailants monday police officials said although no injuries reported attack caused minor damages building criminal investigation incident launched police searching two suspected attackers \n",
      "실제 요약 : turkish embassy in denmark attacked with petrol bombs \n",
      "예측 요약 :  turkish police to attack victims of victims\n",
      "\n",
      "\n",
      "원문 : police constable beaten family members local bjp politician madhya pradesh district imposing fine two relatives triple riding police station charge vivek asthana said police arrested two persons charges assaulting government official duty obstructing discharging duty \n",
      "실제 요약 : bjp leader kin thrash cop over fine for traffic violation \n",
      "예측 요약 :  cop who cop thrashed in mp for cop delay in public\n",
      "\n",
      "\n",
      "원문 : congress claimed rjd tried tested ally unlike bihar cm nitish kumar exited grand alliance join nda comes after rjd leader tejashwi yadav said congress leaders may soft corner nitish only congress president rahul gandhi views matter questions alliances congress mlc pc mishra said \n",
      "실제 요약 : rjd tried and tested ally unlike bihar cm nitish congress \n",
      "예측 요약 :  jd jd alliance grand alliance with jd tejashwi\n",
      "\n",
      "\n",
      "원문 : starbucks employee us received handwritten apology card customer returned apologise rude behaviour earlier customer ordered multiple drinks gotten frustrated informed business drink carriers addition refused take trash due health code violations \n",
      "실제 요약 : starbucks staff gets apology note from customer \n",
      "예측 요약 :  starbucks apologises for us employee over cr\n",
      "\n",
      "\n",
      "원문 : indian tennis player rohan bopanna took instagram share picture roadside eatery named roger federer sweets caption secret food long successful career notably federer became oldest number one men singles player last month reacting user wrote not know roger indian food endorsements \n",
      "실제 요약 : bopanna shares pic of named after federer \n",
      "예측 요약 :  bopanna shares picture of tennis with federer for the first time\n",
      "\n",
      "\n",
      "원문 : pakistan defence minister khan wednesday said country not act hafiz saeed led jamaat ud dawah falah insaniat foundation under pressure us pakistan banned companies individuals making donations jud organisations un security council sanctions list after serious added \n",
      "실제 요약 : action against hafiz saeed not under us pressure pakistan \n",
      "예측 요약 :  pak rejects hafiz saeed for not hafiz saeed\n",
      "\n",
      "\n",
      "원문 : us president donald trump nominee jim bridenstine officially took office nasa th administrator after sworn vice president mike pence monday bridenstine former navy pilot vote last week first nasa chief non scientific background nasa represents best united states america said bridenstine while swearing \n",
      "실제 요약 : trump nominee st nasa chief without background \n",
      "예측 요약 :  trump signs new vice president of naidu\n",
      "\n",
      "\n",
      "원문 : congress mp shashi tharoor wednesday said would introduce private member bill lok sabha next year making stalking non bailable offence private member bill proposes make offence gender neutral guided team lawyers activists people feedback campaign launched following chandigarh stalking case august \n",
      "실제 요약 : will move bill making stalking non bailable shashi tharoor \n",
      "예측 요약 :  tharoor to bill to ban on gender ban on jan\n",
      "\n",
      "\n",
      "원문 : days after arrest father robin connection alleged rape minor girl kerala kannur priest two nuns accused covering matter surrendered before police friday rape survivor gave birth child after raped year old priest arrested february \n",
      "실제 요약 : priest nuns accused of covering up minor rape surrender \n",
      "예측 요약 :  rape accused of raping minor girl in rape case\n",
      "\n",
      "\n",
      "원문 : women rights activist desai arrived cochin today visit sabarimala temple blocked protesters laid siege airport desai stuck airport hours said go ahead come may written kerala cm pinarayi seeking protection journey sabarimala \n",
      "실제 요약 : activist heading to sabarimala stuck at airport for hrs \n",
      "예측 요약 :  women rights to enter sabarimala temple amid threats\n",
      "\n",
      "\n",
      "원문 : praising president donald trump decision move us embassy tel aviv jerusalem israeli prime minister benjamin netanyahu said trump remembered ages also compared trump former us president harry first world leader recognise jewish state \n",
      "실제 요약 : trump will be remembered through israel pm netanyahu \n",
      "예측 요약 :  trump to be called for the first time in jerusalem\n",
      "\n",
      "\n",
      "원문 : after priyanka gandhi vadra entered active politics shiv sena friday said priyanka emerge queen plays cards well added priyanka bears resemblance grandmother indira gandhi looks manner speaking therefore congress surely benefit hindi \n",
      "실제 요약 : if priyanka plays her cards well she will emerge as queen sena \n",
      "예측 요약 :  priyanka gandhi is like upa shah\n",
      "\n",
      "\n",
      "원문 : vidya balan said although not abuse real life quite enjoyed abusing film begum jaan however added would abuse people got groped train took college days turned around slapped people abused hindi jo ho said vidya \n",
      "실제 요약 : abusing in jaan vidya balan \n",
      "예측 요약 :  was told to be like to be vidya balan\n",
      "\n",
      "\n",
      "원문 : after un unanimously passed new sanctions north korea friday us president donald trump tweeted world wants peace not death sanctions imposed test launch intercontinental ballistic missile north korea last month meanwhile north korea called sanctions act war claiming us terrified nuclear force \n",
      "실제 요약 : the world wants peace not death trump on un korea vote \n",
      "예측 요약 :  north korea to make us nuclear deal with north korea\n",
      "\n",
      "\n",
      "원문 : expressing anguish death year old man srinagar jammu kashmir cm mehbooba mufti sunday asked security forces exercise maximum restraint provocative situations asked follow standard operating procedures cases comes after series videos showing alleged brutality armed forces went viral social media \n",
      "실제 요약 : cm asks armed forces to exercise maximum \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 요약 :  up cm slams mamata over death threats for security\n",
      "\n",
      "\n",
      "원문 : fbi top secret security clearance syria married key isis operative assigned investigate intelligence agency revealed greene lied fbi going warned new husband under investigation however fled back us after realising mistake \n",
      "실제 요약 : fbi agent married isis she was investigating \n",
      "예측 요약 :  fbi releases journo over syria journalist murder\n",
      "\n",
      "\n",
      "원문 : former australia captain steve smith set undergo elbow surgery expected wear brace least six weeks before rehabilitation smith serving suspension international cricket suffered elbow injury while playing bangladesh premier league smith david warner suspensions set end march \n",
      "실제 요약 : smith to undergo surgery to wear brace for at least weeks \n",
      "예측 요약 :  steve smith made steve smith for surgery reports\n",
      "\n",
      "\n",
      "원문 : indian tennis player leander paes india first only olympic medal tennis form bronze medal atlanta olympics august paes bronze medal playoff match after progressed semi final men singles tournament lost eventual gold medallist andre agassi \n",
      "실제 요약 : paes won india first and only tennis olympic medal \n",
      "예측 요약 :  paes wins india st medal at olympics\n",
      "\n",
      "\n",
      "원문 : russian president vladimir putin not invited meeting hosted us president donald trump united nations reforms according russian officials countries reportedly invited trump meeting only sign declaration backing un chief antonio guterres efforts reform world body notably trump earlier called un under performer \n",
      "실제 요약 : putin not invited to trump hosted meeting on un reform \n",
      "예측 요약 :  putin will not have played in us president trump\n",
      "\n",
      "\n",
      "원문 : warren buffett billionaire chairman chief executive officer berkshire hathaway said insured losses hurricane harvey could climb much billion nobody good feel losses said high proportion losses insured losses compared events added \n",
      "실제 요약 : losses from harvey could reach billion buffett \n",
      "예측 요약 :  billionaire will be billionaire buffett\n",
      "\n",
      "\n",
      "원문 : rising pune supergiant captain steve smith scored unbeaten ball help team chase ipl encounter mumbai indians thursday mumbai put total nitish rana hardik pandya jos buttler scoring mumbai indians kieron pollard failed defend runs match final \n",
      "실제 요약 : smith unbeaten helps pune register their st ipl win \n",
      "예측 요약 :  smith misses ton ton helps mi get over mi win over\n",
      "\n",
      "\n",
      "원문 : addressing election rally gujarat pm modi sunday said people send congress resort next five years reference congress sent gujarat mlas bengaluru resort ahead rajya sabha elections pm modi accused congress not interested people gujarat \n",
      "실제 요약 : send congress to resort for yrs pm modi at gujarat rally \n",
      "예측 요약 :  congress has no corruption pm modi in gujarat pm modi\n",
      "\n",
      "\n",
      "원문 : addressing gathering poll bound karnataka prime minister narendra modi said bjp highest number mps belonging sc st communities asserting congress nothing honour br ambedkar pm modi added taking inspiration great saints today trying fulfil baba saheb dream powerful nation \n",
      "실제 요약 : bjp has highest number of mps from sc st pm \n",
      "예측 요약 :  pm modi is the most gujarat pm modi on taka poll\n",
      "\n",
      "\n",
      "원문 : india online vendors association decided stop raising concerns payments pricing issues alleging government favours marketplaces like amazon flipkart realised cannot anything apart shouting issues deaf ears representative said per government not seem interested solving things \n",
      "실제 요약 : govt favours amazon flipkart alleges online vendors body \n",
      "예측 요약 :  no evidence on flipkart govt on flipkart govt\n",
      "\n",
      "\n",
      "원문 : senior ips officer modi batch ips officer appointed new director general national investigation agency previously served additional director cbi also part special investigation team probed gujarat riots cases giving prime minister narendra modi clean chit \n",
      "실제 요약 : modi appointed as the new director general of nia \n",
      "예측 요약 :  former ips officer appointed cbi officer in west bengal\n",
      "\n",
      "\n",
      "원문 : government privatise ongc rather give away producing oil gas fields private firms company executives said would give government enough revenue meet disinvestment target bring efficient private sector management added notably government planning give away fields raise output \n",
      "실제 요약 : ongc do not sell off oil fields company officials \n",
      "예측 요약 :  govt proposes support to buy stake in coal for power\n",
      "\n",
      "\n",
      "원문 : congress leader sandeep dikshit while expressing displeasure towards nitish kumar decision switching alliance bjp said respected leader but working amit shah servant believe respected jd leaders leave party dikshit added notably nitish kumar led jd saturday formally accepted bjp invitation join nda \n",
      "실제 요약 : nitish kumar working as amit shah servant congress \n",
      "예측 요약 :  congress is not alliance with jd congress leader\n",
      "\n",
      "\n",
      "원문 : pakistan prime minister world cup winning captain imran khan congratulated team india captain virat kohli test series victory australia congratulations virat kohli indian cricket team first ever win subcontinent team test series australia tweeted notably series st asian team australia \n",
      "실제 요약 : pak pm imran khan congratulates virat kohli for record series win \n",
      "예측 요약 :  kohli kohli kohli wish kohli to take india in test series\n",
      "\n",
      "\n",
      "원문 : pakistan launch space programme next year reduce dependency foreign satellites civil military purposes keep eye india according reports budget country space agency year expected pakistani rs billion pakistan also establish space centres karachi lahore islamabad \n",
      "실제 요약 : pakistan to launch its own space programme next year \n",
      "예측 요약 :  india to launch its own base by pakistan reports\n",
      "\n",
      "\n",
      "원문 : actress kajol took social media share picture son yug occasion seventh birthday wednesday milk always make life fun happy birthday milk moustache wrote along side photo yug kajol second child husband ajay devgn after year old daughter nysa \n",
      "실제 요약 : happy birthday to my milk moustache kajol on son birthday \n",
      "예측 요약 :  kajol shares pic with daughter abram on her birthday\n",
      "\n",
      "\n",
      "원문 : following year old opener prithvi shaw injury year old batsman hanuma vihari said ready bat position captain asks open scored fifty england given chance would like convert century vihari added vihari also picked three wickets fifth india england test \n",
      "실제 요약 : if my captain asks me to open will vihari \n",
      "예측 요약 :  shaw will bat to bat with bat again shaw on shaw\n",
      "\n",
      "\n",
      "원문 : year saw flipkart co founder binny bansal replaced ceo company former tiger global executive kalyan krishnamurthy viral fever founder ceo arunabh kumar stepped role following multiple sexual harassment allegations further flipkart chief operating officer nitin seth also quit homegrown commerce startup citing personal reasons \n",
      "실제 요약 : who were top indian startup executives to resign in \n",
      "예측 요약 :  flipkart binny bansal quits flipkart board after sexual harassment\n",
      "\n",
      "\n",
      "원문 : facebook ceo mark zuckerberg took one year turn millionaire billionaire according study based forbes data zuckerberg youngest self made billionaire forbes billionaires list debuted age zuckerberg currently world th richest person fortune billion \n",
      "실제 요약 : mark zuckerberg became billionaire from millionaire in yr \n",
      "예측 요약 :  zuckerberg named facebook of facebook billionaire\n",
      "\n",
      "\n",
      "원문 : after release video footage surgical strikes indian army congress spokesperson randeep surjewala accused pm narendra modi led government using strikes win votes added whenever government amit shah bjp starts failing misuse army political benefit \n",
      "실제 요약 : pm modi govt using surgical strikes to win votes congress \n",
      "예측 요약 :  surgical strikes in surgical strikes rahul on surgical strikes\n",
      "\n",
      "\n",
      "원문 : after pm narendra modi said government take decision ordinance ram mandir construction judicial process concludes vhp leader alok kumar said hindus cannot wait till court decide ram mandir kumar added only way forward enact legislation clearing way construction temple \n",
      "실제 요약 : hindus cannot wait till for verdict vhp on ram mandir \n",
      "예측 요약 :  ram temple will not be built by ram mandir ram mandir\n",
      "\n",
      "\n",
      "원문 : technology giant apple decided end hosting annual apple music festival previously known festival london years after launch show first held designed boost business artists like adele one direction ed sheeran lady gaga performed festival decade long run \n",
      "실제 요약 : apple ends its annual music festival after years \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 요약 :  apple to launch new collection of the year end\n",
      "\n",
      "\n",
      "원문 : mukesh ambani led reliance industries friday posted year year increase consolidated net profit crore june quarter company operational revenue also increased lakh crore reliance jio posted profit second quarter row crore quarter ended june \n",
      "실제 요약 : mukesh ambani ril posts rise in profit to cr \n",
      "예측 요약 :  reliance jio profit rises to crore in march quarter\n",
      "\n",
      "\n",
      "원문 : delhi based woman duped bachelors haryana pretext finding beautiful brides surrendered sonipat court accused collected man however men gathered mass wedding function found accused run away money \n",
      "실제 요약 : delhi woman who duped surrenders in court \n",
      "예측 요약 :  woman files fir against woman for gurugram woman\n",
      "\n",
      "\n",
      "원문 : whose stock singapore worst performing rallied year lead benchmark times index firm made comeback after contracts worth million first quarter million worth orders last year share price gain five times index \n",
      "실제 요약 : worst performing singapore stock up to be best \n",
      "예측 요약 :  sensex posts record high of the year high of\n",
      "\n",
      "\n",
      "원문 : thief kerala returned stolen jewellery owners along apology note read please forgive circumstances sorry owners filed police complaint finding ornaments missing home after returning wedding thief thursday left stolen jewels gate \n",
      "실제 요약 : kerala thief returns stolen along with apology note \n",
      "예측 요약 :  thief who stole food from ex employee apologises for stealing\n",
      "\n",
      "\n",
      "원문 : emraan hashmi cheat india not hero worshipping but focuses mainly story content according times plot became convenient lost track after interval wrote while hindustan times said film tries appear funny without smart rated times ht \n",
      "실제 요약 : emraan hashmi starrer why cheat india hits the theatres \n",
      "예측 요약 :  emraan hashmi emraan hashmi baadshaho to be auctioned\n",
      "\n",
      "\n",
      "원문 : mohammad shami wife hasin jahan filed case pacer court tuesday seeking lakh per month maintenance loss ends would delhi meet never forget way behaved said jahan lawyer claimed money pay monthly expenses \n",
      "실제 요약 : jahan demands lakh month as maintenance from shami \n",
      "예측 요약 :  shami wife claims she will be renamed by bcci\n",
      "\n",
      "\n",
      "원문 : two priests murdered one critically injured temple uttar pradesh district led protestors setting shops ablaze pelting stones police police said priests attacked sleeping one tongue cut meanwhile two policemen suspended after protest \n",
      "실제 요약 : protests in up after priests stabbed to death in temple \n",
      "예측 요약 :  injured as man clash with up at police station in up\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-discretion",
   "metadata": {},
   "source": [
    "## Summa을 이용해서 추출적 요약해보기\n",
    "\n",
    "추상적 요약은 추출적 요약과는 달리 문장의 표현력을 다양하게 가져갈 수 있지만, 추출적 요약에 비해서 난이도가 높고, 추출적 요약은 추상적 요약에 비해 난이도가 낮고 기존 문장에서 문장을 꺼내오는 것이므로 잘못된 요약이 나올 가능성이 낮다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-parliament",
   "metadata": {},
   "source": [
    "데이터 다운로드하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "spectacular-movie",
   "metadata": {},
   "outputs": [],
   "source": [
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-brother",
   "metadata": {},
   "source": [
    "매트릭스 시놉시스를 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "working-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = requests.get('http://rare-technologies.com/the_matrix_synopsis.txt').text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-topic",
   "metadata": {},
   "source": [
    "출력결과 일부만 저장해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "running-architect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The screen is filled with green, cascading code which gives way to the title, The Matrix.\r\n",
      "\r\n",
      "A phone rings and text appears on the screen: \"Call trans opt: received. 2-19-98 13:24:18 REC: Log>\" As a conversation takes place between Trinity (Carrie-Anne Moss) and Cypher (Joe Pantoliano), two free humans, a table of random green numbers are being scanned and individual numbers selected, creating a series of digits not unlike an ordinary phone number, as if a code is being deciphered or a call is being traced.\r\n",
      "\r\n",
      "Trinity discusses some unknown person. Cypher taunts Trinity, suggesting she enjoys watching him. Trinity counters that \"Morpheus (Laurence Fishburne) says he may be 'the One',\" just as the sound of a number being selected alerts Trinity that someone may be tracing their call. She ends the call.\r\n",
      "\r\n",
      "Armed policemen move down a darkened, decrepit hallway in the Heart O' the City Hotel, their flashlight beam bouncing just ahead of them. They come to room 303, kick down the door and find a woman dressed in black, facing away from them. It's Trinity. She brings her hands up from the laptop she's working on at their command.\r\n",
      "\r\n",
      "Outside the hotel a car drives up and three agents appear in neatly pressed black suits. They are Agent Smith (Hugo Weaving), Agent Brown (Paul Goddard), and Agent Jones (Robert Taylor). Agent Smith and the presiding police lieutenant argue. Agent Smith admonishes the policeman that they were given specific orders to contact the agents first, for their\n"
     ]
    }
   ],
   "source": [
    "print(text[:1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-conditioning",
   "metadata": {},
   "source": [
    "summarize 사용하여 원문의 0.005%만을 출력해도록 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "prepared-enterprise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines:\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "print('headlines:')\n",
    "print(summarize(text, ratio=0.005))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-struggle",
   "metadata": {},
   "source": [
    "split 인자의 값을 True로 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cubic-belfast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines:\n",
      "['Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.', 'Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.']\n"
     ]
    }
   ],
   "source": [
    "print('headlines:')\n",
    "print(summarize(text, ratio=0.005, split=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-payment",
   "metadata": {},
   "source": [
    "단어를 50개만 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "turkish-establishment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines:\n",
      "Trinity takes Neo to Morpheus.\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "print('headlines:')\n",
    "print(summarize(text, words=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-match",
   "metadata": {},
   "source": [
    "### 회고\n",
    "\n",
    "확실히 자연어 처리부분이 컴퓨터 비전에 비해서 이해도가 떨어지는 느낌이 있다.\n",
    "지난번에 작사가 인공지능 만들기 노드에서두 망했었는뎅... \n",
    "\n",
    "단순히 앞에 예문에서 내용을 그대로 따라가면서 진행했던 노드인데다가... \n",
    "\n",
    "자연어쪽은 학습시키는데 시간이 많이 걸려서 중간에 끊고 진행하기가 힘들어서 더욱 노드를 진행하기가 힘들었다.\n",
    "\n",
    "추상적 요약보다는 뭔가 추출적 요약부분이 기존에 인간의 행동패턴을 모방한것 같은 느낌이 들었다.\n",
    "\n",
    "TEXT의 적절한 최대 최소 길이를 선택하는 부분도 아직까지 잘 모르겟다. 길이분포를 시각화 했을때 가운데 점을 기준으로 해야하는지, \n",
    "\n",
    "내용을 담고잇는 마지막 부분을 기준으로 해야하는지, 샘플비율을 최대한 많이 잡아 주는게 좋은것인지... 아직도 헷갈리는 부분이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-nirvana",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
